{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "236b68fb",
   "metadata": {},
   "source": [
    "## prepro v1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e006b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 11:56:50.571500: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-13 11:56:54.304540: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "import matplotlib.patches as mpatches\n",
    "import time\n",
    "\n",
    "# Classifier Libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import collections\n",
    "\n",
    "\n",
    "# Other Librariest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import precision_score, recall_score, precision_recall_curve, auc, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88161fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('../raw_data/creditcard.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "167a706b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1.copy()\n",
    "df['Hour'] = (df['Time'] // 3600) % 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "241f6580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class']\n",
    "\n",
    "# Split data into training and test sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Apply SMOTE to the training set\n",
    "smote = SMOTE(sampling_strategy=0.2, random_state=42)  # Adjust ratio if needed\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "437976d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RobustScaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Apply scaling only to 'Time' and 'Amount'\n",
    "X_train_smote[['Time', 'Amount']] = scaler.fit_transform(X_train_smote[['Time', 'Amount']])\n",
    "X_test[['Time', 'Amount']] = scaler.transform(X_test[['Time', 'Amount']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1add4fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transform the 'Amount' column to reduce skewness\n",
    "X_train_smote['Log_Amount'] = np.log1p(X_train_smote['Amount'])\n",
    "X_test['Log_Amount'] = np.log1p(X_test['Amount'])\n",
    "\n",
    "# Drop the original 'Amount' column if needed\n",
    "X_train_smote.drop(columns=['Amount'], inplace=True)\n",
    "X_test.drop(columns=['Amount'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf5c4129",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply cyclical transformation\n",
    "X_train_smote[\"Hour_sin\"] = np.sin(2 * np.pi * X_train_smote[\"Hour\"] / 24)\n",
    "X_train_smote[\"Hour_cos\"] = np.cos(2 * np.pi * X_train_smote[\"Hour\"] / 24)\n",
    "\n",
    "X_test[\"Hour_sin\"] = np.sin(2 * np.pi * X_test[\"Hour\"] / 24)\n",
    "X_test[\"Hour_cos\"] = np.cos(2 * np.pi * X_test[\"Hour\"] / 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "defd4203",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_smote.drop(columns=[\"Hour\"], inplace=True)\n",
    "X_test.drop(columns=[\"Hour\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b60172f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_smote['Class'] = y_train_smote\n",
    "# Compute correlation matrix\n",
    "correlation_matrix = X_train_smote.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c93c6190",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = X_train_smote.corr()['Class'].sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ca4c030",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_corr_features = ['V26', 'V22', 'V25', 'V23', 'V13', 'Time']\n",
    "X_train_smote.drop(columns=low_corr_features, inplace=True)\n",
    "X_test.drop(columns=low_corr_features, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43b82824",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute the absolute correlation with the target column\n",
    "target_corr = correlation_matrix['Class'].abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix to avoid redundancy\n",
    "upper = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Find pairs of features with correlation greater than 0.85\n",
    "high_corr_pairs = []\n",
    "for column in upper.columns:\n",
    "    high_corr_pairs += [(column, other) for other in upper.index if upper[column][other] > 0.85]\n",
    "\n",
    "# For each pair of highly correlated features, drop the one with lower correlation to the target\n",
    "columns_to_drop = []\n",
    "for feature1, feature2 in high_corr_pairs:\n",
    "    if abs(target_corr[feature1]) < abs(target_corr[feature2]):\n",
    "        columns_to_drop.append(feature1)\n",
    "    else:\n",
    "        columns_to_drop.append(feature2)\n",
    "\n",
    "# Drop the selected columns from X_train_smote\n",
    "X_train_smote.drop(columns=columns_to_drop, inplace=True)\n",
    "X_train_smote.drop(columns=['Class'], inplace=True)\n",
    "X_test.drop(columns=columns_to_drop, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6be39fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model LogisticRegression PreproV1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3ebfea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train the model\n",
    "model_logreg_prepro15 = LogisticRegression(\n",
    "    class_weight='balanced',  # Handle imbalance class_weight='balanced'    automatically compensates for class imbalance.\n",
    "\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "model_logreg_prepro15.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "959d213e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(272941, 23)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_smote.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c6cf715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56962, 23)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9561c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall(LogReg V1.5): 0.9082\n",
      "PR AUC(LogReg V1.5): 0.7220\n"
     ]
    }
   ],
   "source": [
    "#  Compute Recallfrom\n",
    "from sklearn.metrics import recall_score, precision_recall_curve, auc\n",
    "\n",
    "# Predict labels\n",
    "y_pred = model_logreg_prepro15.predict(X_test)\n",
    "recall_logreg_prepro15 = recall_score(y_test, y_pred)\n",
    "\n",
    "# Compute PR AUC (Precision-Recall AUC)\n",
    "y_probs = model_logreg_prepro15.predict_proba(X_test)[:, 1]\n",
    "precision, recall_curve, _ = precision_recall_curve(y_test, y_probs)\n",
    "pr_auc = auc(recall_curve, precision)\n",
    "\n",
    "# Print results\n",
    "print(f\"Recall(LogReg V1.5): {recall_logreg_prepro15:.4f}\")  # Исправлено\n",
    "print(f\"PR AUC(LogReg V1.5): {pr_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90720474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=42, ...)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the XGBoost model PrePro V15\n",
    "import xgboost as xgb\n",
    "\n",
    "# Create the XGBoost model\n",
    "model_xgb_preprov15 = xgb.XGBClassifier(\n",
    "    objective=\"binary:logistic\",  # This is for binary classification (yes/no)\n",
    "    scale_pos_weight=len(y_train_smote[y_train_smote == 0]) / len(y_train_smote[y_train_smote == 1]),  \n",
    "    # This helps when we have more examples of one class than the other (class imbalance)\n",
    "    \n",
    "    eval_metric=\"logloss\",  # This checks how good the model is (lower is better)\n",
    "    random_state=42,  # This makes sure we get the same results every time we run the model\n",
    "    use_label_encoder=False  # This removes a warning message\n",
    ")\n",
    "\n",
    "# Train (fit) the model with the training data\n",
    "model_xgb_preprov15.fit(X_train_smote, y_train_smote)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c299eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81f2f5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall (XGBoost V1.5): 0.8571\n",
      "PR AUC (XGBoost V1.5): 0.8736\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred_xgb = model_xgb_preprov15.predict(X_test)\n",
    "\n",
    "# Calculate Recall\n",
    "recall_xgb = recall_score(y_test, y_pred_xgb)\n",
    "# Recall tells us how many positive cases we found correctly\n",
    "\n",
    "# Get probabilities for PR AUC calculation\n",
    "y_probs_xgb = model_xgb_preprov15.predict_proba(X_test)[:, 1]\n",
    "# predict_proba() gives probabilities for both classes\n",
    "# [:, 1] means we take only the probability for the positive class (1)\n",
    "\n",
    "# Calculate Precision-Recall Curve\n",
    "precision, recall_curve, _ = precision_recall_curve(y_test, y_probs_xgb)\n",
    "\n",
    "# Compute PR AUC (Area Under the Precision-Recall Curve)\n",
    "pr_auc_xgb = auc(recall_curve, precision)\n",
    "\n",
    "# Print results\n",
    "print(f\"Recall (XGBoost V1.5): {recall_xgb:.4f}\")\n",
    "# Shows the recall score (higher is better)\n",
    "\n",
    "print(f\"PR AUC (XGBoost V1.5): {pr_auc_xgb:.4f}\")\n",
    "# Shows PR AUC (higher is better, closer to 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e2aa2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Model for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8692579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c641a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall (Random Forest prepro15): 0.8061\n",
      "PR AUC (Random Forest prepro15): 0.8682\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import recall_score, precision_recall_curve, auc\n",
    "\n",
    "# Create the model\n",
    "model_rf_prepro15 = RandomForestClassifier(\n",
    "    n_estimators=100,  # Number of trees\n",
    "    class_weight=\"balanced\",  # Adjust for class imbalance\n",
    "    random_state=42  # Ensure reproducibility\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model_rf_prepro15.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_rf_prepro15 = model_rf_prepro15.predict(X_test)\n",
    "\n",
    "# Compute recall\n",
    "recall_rf_prepro15 = recall_score(y_test, y_pred_rf_prepro15)\n",
    "\n",
    "# Compute PR AUC\n",
    "y_probs_rf_prepro15 = model_rf_prepro15.predict_proba(X_test)[:, 1]\n",
    "precision, recall_curve, _ = precision_recall_curve(y_test, y_probs_rf_prepro15)\n",
    "pr_auc_rf_prepro15 = auc(recall_curve, precision)\n",
    "\n",
    "# Print results\n",
    "print(f\"Recall (Random Forest prepro15): {recall_rf_prepro15:.4f}\")\n",
    "print(f\"PR AUC (Random Forest prepro15): {pr_auc_rf_prepro15:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1652eae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.10512 | val_0_logloss: 0.02136 |  0:00:26s\n",
      "epoch 1  | loss: 0.04604 | val_0_logloss: 0.01717 |  0:00:55s\n",
      "epoch 2  | loss: 0.03811 | val_0_logloss: 0.02178 |  0:01:16s\n",
      "epoch 3  | loss: 0.03072 | val_0_logloss: 0.01046 |  0:01:43s\n",
      "epoch 4  | loss: 0.02583 | val_0_logloss: 0.01754 |  0:02:10s\n",
      "Stop training because you reached max_epochs = 5 with best_epoch = 3 and best_val_0_logloss = 0.01046\n"
     ]
    }
   ],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.metrics import recall_score, precision_recall_curve, auc\n",
    "import numpy as np\n",
    "\n",
    "# Create the TabNet model with name prepro15\n",
    "model_tabnet_prepro15 = TabNetClassifier(\n",
    "    optimizer_params=dict(lr=0.02),  # Learning rate (how fast the model learns)\n",
    "    seed=42  # Fix the random seed for the same results every time\n",
    ")\n",
    "\n",
    "# Convert data to NumPy (TabNet works with NumPy, not Pandas)\n",
    "X_train_np = X_train_smote.to_numpy()\n",
    "y_train_np = y_train_smote.to_numpy().ravel()  # Fix the shape issue\n",
    "X_test_np = X_test.to_numpy()\n",
    "y_test_np = y_test.to_numpy().ravel()  # Fix the shape issue\n",
    "\n",
    "# Train the model\n",
    "model_tabnet_prepro15.fit(\n",
    "    X_train_np, y_train_np,\n",
    "    eval_set=[(X_test_np, y_test_np)],  # Check model performance on test data\n",
    "    eval_metric=['logloss'],  # Use log loss to check errors\n",
    "    max_epochs=5,  # Train for 100 rounds\n",
    "    patience=5,  # Stop early if no improvement for 10 rounds\n",
    "    batch_size=1024,  # Number of examples in each training step\n",
    "    virtual_batch_size=128,  # For faster learning\n",
    "    num_workers=0  # Number of CPU cores used (0 means auto)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eb8875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall (TabNet prepro15): 0.8776\n",
      "PR AUC (TabNet prepro15): 0.8058\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test data\n",
    "y_pred_tabnet_prepro15 = model_tabnet_prepro15.predict(X_test_np)\n",
    "\n",
    "# Calculate Recall\n",
    "recall_tabnet_prepro15 = recall_score(y_test_np, y_pred_tabnet_prepro15)\n",
    "# Recall tells us how many positive cases we found correctly\n",
    "\n",
    "# Get probabilities for PR AUC calculation\n",
    "y_probs_tabnet_prepro15 = model_tabnet_prepro15.predict_proba(X_test_np)[:, 1]\n",
    "# predict_proba() gives probabilities for both classes\n",
    "# [:, 1] means we take only the probability for the positive class (1)\n",
    "\n",
    "# Calculate Precision-Recall Curve\n",
    "precision, recall_curve, _ = precision_recall_curve(y_test_np, y_probs_tabnet_prepro15)\n",
    "\n",
    "# Compute PR AUC (Area Under the Precision-Recall Curve)\n",
    "pr_auc_tabnet_prepro15 = auc(recall_curve, precision)\n",
    "\n",
    "# Print results\n",
    "print(f\"Recall (TabNet prepro15): {recall_tabnet_prepro15:.4f}\")\n",
    "print(f\"PR AUC (TabNet prepro15): {pr_auc_tabnet_prepro15:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "edb1b727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall(LogReg V1.5): 0.9082\n",
      "PR AUC(LogReg V1.5): 0.7220\n",
      "Recall (XGBoost V1.5): 0.8571\n",
      "PR AUC (XGBoost V1.5): 0.8736\n",
      "Recall (Random Forest prepro15): 0.8061\n",
      "PR AUC (Random Forest prepro15): 0.8682\n",
      "Recall (TabNet prepro15): 0.8776\n",
      "PR AUC (TabNet prepro15): 0.8058\n"
     ]
    }
   ],
   "source": [
    "print(f\"Recall(LogReg V1.5): {recall_logreg_prepro15:.4f}\")  # Исправлено\n",
    "print(f\"PR AUC(LogReg V1.5): {pr_auc:.4f}\")\n",
    "print(f\"Recall (XGBoost V1.5): {recall_xgb:.4f}\")\n",
    "print(f\"PR AUC (XGBoost V1.5): {pr_auc_xgb:.4f}\")\n",
    "print(f\"Recall (Random Forest prepro15): {recall_rf_prepro15:.4f}\")\n",
    "print(f\"PR AUC (Random Forest prepro15): {pr_auc_rf_prepro15:.4f}\")\n",
    "\n",
    "print(f\"Recall (TabNet prepro15): {recall_tabnet_prepro15:.4f}\")\n",
    "print(f\"PR AUC (TabNet prepro15): {pr_auc_tabnet_prepro15:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36300d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomguard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
