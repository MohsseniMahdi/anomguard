{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Classifier Libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import collections\n",
    "\n",
    "\n",
    "# Other Librariest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import precision_score, recall_score, precision_recall_curve, auc, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anomguard.ml_logic.preprocessing  import preprocessing_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('../raw_data/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hour'] = (df['Time'] // 3600) % 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Separate features and target variable\n",
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class']\n",
    "\n",
    "# # Split data into training and test sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed, X_test_transformed, y_train_smote = preprocessing_smote(X_train=X_train, X_test=X_test, y_train=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(272941, 32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56962, 32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(272941,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_smote.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize RobustScaler\n",
    "# scaler = RobustScaler()\n",
    "\n",
    "# # Apply scaling only to 'Time' and 'Amount'\n",
    "# X_train_smote[['Time', 'Amount']] = scaler.fit_transform(X_train_smote[['Time', 'Amount']])\n",
    "# X_test[['Time', 'Amount']] = scaler.transform(X_test[['Time', 'Amount']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Log transform the 'Amount' column to reduce skewness\n",
    "# X_train_smote['Log_Amount'] = np.log1p(X_train_smote['Amount'])\n",
    "# X_test['Log_Amount'] = np.log1p(X_test['Amount'])\n",
    "\n",
    "# # Drop the original 'Amount' column if needed\n",
    "# X_train_smote.drop(columns=['Amount'], inplace=True)\n",
    "# X_test.drop(columns=['Amount'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Apply cyclical transformation\n",
    "# X_train_smote[\"Hour_sin\"] = np.sin(2 * np.pi * X_train_smote[\"Hour\"] / 24)\n",
    "# X_train_smote[\"Hour_cos\"] = np.cos(2 * np.pi * X_train_smote[\"Hour\"] / 24)\n",
    "\n",
    "# X_test[\"Hour_sin\"] = np.sin(2 * np.pi * X_test[\"Hour\"] / 24)\n",
    "# X_test[\"Hour_cos\"] = np.cos(2 * np.pi * X_test[\"Hour\"] / 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_smote.drop(columns=[\"Hour\"], inplace=True)\n",
    "# X_test.drop(columns=[\"Hour\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(272941, 32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56962, 32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logreg_prepro1 = LogisticRegression(\n",
    "    class_weight='balanced',  # Handle imbalance class_weight='balanced'    automatically compensates for class imbalance.\n",
    "\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "model_logreg_prepro1.fit(X_train_transformed, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'Log_Amount', 'Hour_sin', 'Hour_cos', 'V1', 'V2', 'V3', 'V4',\n",
       "       'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15',\n",
       "       'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25',\n",
       "       'V26', 'V27', 'V28'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'Log_Amount', 'Hour_sin', 'Hour_cos', 'V1', 'V2', 'V3', 'V4',\n",
       "       'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15',\n",
       "       'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25',\n",
       "       'V26', 'V27', 'V28'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_transformed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall(LogReg V1.0): 0.9703\n",
      "PR AUC(LogReg V1.0): 0.9929\n"
     ]
    }
   ],
   "source": [
    "#  Compute Recallfrom\n",
    "from sklearn.metrics import recall_score, precision_recall_curve, auc\n",
    "\n",
    "# Predict labels\n",
    "y_pred = model_logreg_prepro1.predict(X_train_transformed)\n",
    "recall_logreg_prepro1 = recall_score(y_train_smote, y_pred)\n",
    "\n",
    "# Compute PR AUC (Precision-Recall AUC)\n",
    "y_probs = model_logreg_prepro1.predict_proba(X_train_transformed)[:, 1]\n",
    "precision, recall_curve, _ = precision_recall_curve(y_train_smote, y_probs)\n",
    "pr_auc = auc(recall_curve, precision)\n",
    "\n",
    "# Print results\n",
    "print(f\"Recall(LogReg V1.0): {recall_logreg_prepro1:.4f}\")  # Исправлено\n",
    "print(f\"PR AUC(LogReg V1.0): {pr_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(272941,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_smote.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=42, ...)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Create the XGBoost model\n",
    "model_xgb_preprov1 = xgb.XGBClassifier(\n",
    "    objective=\"binary:logistic\",  \n",
    "    scale_pos_weight=len(y_train_smote[y_train_smote == 0]) / len(y_train_smote[y_train_smote == 1]),  \n",
    "    \n",
    "    \n",
    "    eval_metric=\"logloss\",  # This checks how good the model is (lower is better)\n",
    "    random_state=42,  # This makes sure we get the same results every time we run the model\n",
    "    use_label_encoder=False  # This removes a warning message\n",
    ")\n",
    "\n",
    "# Train (fit) the model with the training data\n",
    "model_xgb_preprov1.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall (XGBoost V1.0): 0.8469\n",
      "PR AUC (XGBoost V1.0): 0.8714\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred_xgb = model_xgb_preprov1.predict(X_test)\n",
    "\n",
    "# Calculate Recall\n",
    "recall_xgb = recall_score(y_test, y_pred_xgb)\n",
    "# Recall tells us how many positive cases we found correctly\n",
    "\n",
    "# Get probabilities for PR AUC calculation\n",
    "y_probs_xgb = model_xgb_preprov1.predict_proba(X_test)[:, 1]\n",
    "# predict_proba() gives probabilities for both classes\n",
    "# [:, 1] means we take only the probability for the positive class (1)\n",
    "\n",
    "# Calculate Precision-Recall Curve\n",
    "precision, recall_curve, _ = precision_recall_curve(y_test, y_probs_xgb)\n",
    "\n",
    "# Compute PR AUC (Area Under the Precision-Recall Curve)\n",
    "pr_auc_xgb = auc(recall_curve, precision)\n",
    "\n",
    "# Print results\n",
    "print(f\"Recall (XGBoost V1.0): {recall_xgb:.4f}\")\n",
    "# Shows the recall score (higher is better)\n",
    "\n",
    "print(f\"PR AUC (XGBoost V1.0): {pr_auc_xgb:.4f}\")\n",
    "# Shows PR AUC (higher is better, closer to 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall (Random Forest prepro1.0): 0.8163\n",
      "PR AUC (Random Forest prepro1.0): 0.8719\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import recall_score, precision_recall_curve, auc\n",
    "\n",
    "# Create the model\n",
    "model_rf_prepro1 = RandomForestClassifier(\n",
    "    n_estimators=100,  # Number of trees\n",
    "    class_weight=\"balanced\",  # Adjust for class imbalance\n",
    "    random_state=42  # Ensure reproducibility\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model_rf_prepro1.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_rf_prepro1 = model_rf_prepro1.predict(X_test)\n",
    "\n",
    "# Compute recall\n",
    "recall_rf_prepro1 = recall_score(y_test, y_pred_rf_prepro1)\n",
    "\n",
    "# Compute PR AUC\n",
    "y_probs_rf_prepro1 = model_rf_prepro1.predict_proba(X_test)[:, 1]\n",
    "precision, recall_curve, _ = precision_recall_curve(y_test, y_probs_rf_prepro1)\n",
    "pr_auc_rf_prepro1 = auc(recall_curve, precision)\n",
    "\n",
    "# Print results\n",
    "print(f\"Recall (Random Forest prepro1.0): {recall_rf_prepro1:.4f}\")\n",
    "print(f\"PR AUC (Random Forest prepro1.0): {pr_auc_rf_prepro1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.metrics import recall_score, precision_recall_curve, auc\n",
    "import numpy as np\n",
    "\n",
    "# Create the TabNet model with name prepro15\n",
    "model_tabnet_prepro1 = TabNetClassifier(\n",
    "    optimizer_params=dict(lr=0.02),  # Learning rate (how fast the model learns)\n",
    "    seed=42  # Fix the random seed for the same results every time\n",
    ")\n",
    "\n",
    "# Convert data to NumPy (TabNet works with NumPy, not Pandas)\n",
    "X_train_np = X_train_smote.to_numpy()\n",
    "y_train_np = y_train_smote.to_numpy().ravel()  # Fix the shape issue\n",
    "X_test_np = X_test.to_numpy()\n",
    "y_test_np = y_test.to_numpy().ravel()  # Fix the shape issue\n",
    "\n",
    "# Train the model\n",
    "model_tabnet_prepro1.fit(\n",
    "    X_train_np, y_train_np,\n",
    "    eval_set=[(X_test_np, y_test_np)],  # Check model performance on test data\n",
    "    eval_metric=['logloss'],  # Use log loss to check errors\n",
    "    max_epochs=15,  # Train for 100 rounds\n",
    "    patience=5,  # Stop early if no improvement for 10 rounds\n",
    "    batch_size=1024,  # Number of examples in each training step\n",
    "    virtual_batch_size=128,  # For faster learning\n",
    "    num_workers=0  # Number of CPU cores used (0 means auto)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data\n",
    "y_pred_tabnet_prepro1 = model_tabnet_prepro1.predict(X_test_np)\n",
    "\n",
    "# Calculate Recall\n",
    "recall_tabnet_prepro1 = recall_score(y_test_np, y_pred_tabnet_prepro1)\n",
    "# Recall tells us how many positive cases we found correctly\n",
    "\n",
    "# Get probabilities for PR AUC calculation\n",
    "y_probs_tabnet_prepro1 = model_tabnet_prepro1.predict_proba(X_test_np)[:, 1]\n",
    "# predict_proba() gives probabilities for both classes\n",
    "# [:, 1] means we take only the probability for the positive class (1)\n",
    "\n",
    "# Calculate Precision-Recall Curve\n",
    "precision, recall_curve, _ = precision_recall_curve(y_test_np, y_probs_tabnet_prepro1)\n",
    "\n",
    "# Compute PR AUC (Area Under the Precision-Recall Curve)\n",
    "pr_auc_tabnet_prepro1 = auc(recall_curve, precision)\n",
    "\n",
    "# Print results\n",
    "print(f\"Recall (TabNet prepro1.0): {recall_tabnet_prepro1:.4f}\")\n",
    "print(f\"PR AUC (TabNet prepro1.0): {pr_auc_tabnet_prepro1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'recall_logreg_prepro1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecall(LogReg V1.0): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mrecall_logreg_prepro1\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Исправлено\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPR AUC(LogReg V1.0): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpr_auc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecall (XGBoost V1.0): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecall_xgb\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'recall_logreg_prepro1' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"Recall(LogReg V1.0): {recall_logreg_prepro1:.4f}\")  # Исправлено\n",
    "print(f\"PR AUC(LogReg V1.0): {pr_auc:.4f}\")\n",
    "print(f\"Recall (XGBoost V1.0): {recall_xgb:.4f}\")\n",
    "print(f\"PR AUC (XGBoost V1.0): {pr_auc_xgb:.4f}\")\n",
    "print(f\"Recall (Random Forest prepro15): {recall_rf_prepro1:.4f}\")\n",
    "print(f\"PR AUC (Random Forest prepro15): {pr_auc_rf_prepro1:.4f}\")\n",
    "\n",
    "print(f\"Recall (TabNet prepro15): {recall_tabnet_prepro1:.4f}\")\n",
    "print(f\"PR AUC (TabNet prepro15): {pr_auc_tabnet_prepro1:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomguard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
