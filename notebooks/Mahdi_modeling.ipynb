{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import BorderlineSMOTE, SMOTE\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from scipy.stats.mstats import winsorize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### V2 Millan\n",
    "data = pd.read_csv(\"raw_data/creditcard.csv\")\n",
    "\n",
    "# Remove duplicate rows\n",
    "#data = data.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "data['Hour'] = (data['Time'] // 3600) % 24\n",
    "\n",
    "    ## split the data\n",
    "X = data.drop(columns = ['Class'])\n",
    "y = data['Class']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "# Apply SMOTE to the training set\n",
    "smote = SMOTE(sampling_strategy=0.3, random_state=42)  # Adjust ratio if needed\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define function for log transformation\n",
    "log_transformer = FunctionTransformer(lambda X: np.log1p(X), validate=False)\n",
    "# Define cyclical encoding transformation\n",
    "cyclical_transformer = FunctionTransformer(lambda X: np.column_stack((\n",
    "    np.sin(2 * np.pi * X / 24),\n",
    "    np.cos(2 * np.pi * X / 24)\n",
    ")), validate=False)\n",
    "\n",
    "\n",
    "# Define pipeline for 'Amount' - first apply scaling, then log transform\n",
    "amount_pipeline = Pipeline([\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('log_transform', log_transformer)\n",
    "])\n",
    "\n",
    "# Define ColumnTransformer to apply transformations\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "('time_scaler', RobustScaler(), ['Time']),  # Scale 'Time' only\n",
    "('amount_pipeline', amount_pipeline, ['Amount']),  # Apply scaling + log transform to 'Amount'\n",
    "('hour_cyclical', cyclical_transformer, ['Hour'])  # Apply sine and cosine encoding to 'Hour'\n",
    "], remainder='passthrough')  # Keep other columns\n",
    "\n",
    "# Apply the transformation\n",
    "X_train_transformed = preprocessor.fit_transform(X_train_smote)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "X_val_transformed = preprocessor.transform(X_val)\n",
    "\n",
    "# Convert back to DataFrame with proper column\n",
    "columns = ['Time', 'Log_Amount', 'Hour_sin', 'Hour_cos'] + [col for col in X_train_smote.columns if col not in ['Time', 'Amount', 'Hour']]\n",
    "X_train_transformed = pd.DataFrame(X_train_transformed, columns=columns)\n",
    "X_test_transformed = pd.DataFrame(X_test_transformed, columns=columns)\n",
    "X_val_transformed = pd.DataFrame(X_val_transformed, columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_transformed.copy()\n",
    "X_test = X_test_transformed.copy()\n",
    "X_val = X_val_transformed.copy()\n",
    "y_train = y_train_smote.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 15:44:42.294154: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-20 15:44:44.718216: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-20 15:44:55.526357: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1113/1113 [==============================] - 2s 2ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     35544\n",
      "           1       0.67      0.86      0.75        57\n",
      "\n",
      "    accuracy                           1.00     35601\n",
      "   macro avg       0.84      0.93      0.88     35601\n",
      "weighted avg       1.00      1.00      1.00     35601\n",
      "\n",
      "AUC-ROC Score: 0.9781814780593165\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "\n",
    "# Convert classes to numpy array\n",
    "classes = np.array([0, 1])\n",
    "\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train_smote)\n",
    "class_weights_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "\n",
    "\n",
    "# Define the neural network model\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),  # Helps prevent overfitting\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Sigmoid for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['AUC'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_val_transformed, y_val),\n",
    "                    epochs=30, batch_size=64,\n",
    "                    class_weight=class_weights_dict,\n",
    "                    verbose=0)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"AUC-ROC Score:\", roc_auc_score(y_test, y_pred_prob))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 16:28:48.875409: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-20 16:28:49.179867: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "/tmp/ipykernel_107423/3894473765.py:23: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32, verbose=0)\n",
      "2025-03-20 16:28:54.402111: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-20 16:28:54.446171: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-20 16:28:54.462716: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-20 16:28:54.642689: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-20 16:28:54.647659: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-20 16:28:54.702073: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-20 16:28:54.710536: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-20 16:28:54.800854: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-20 16:28:54.815344: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-20 16:28:54.873252: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-20 16:28:54.916391: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-20 16:28:54.968612: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-20 16:28:55.003280: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-20 16:28:55.016211: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-20 16:28:55.078179: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-20 16:28:55.151289: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-20 16:28:55.193145: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-20 16:28:55.213094: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-20 16:28:55.218760: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-20 16:28:55.249652: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-20 16:28:55.300022: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-20 16:28:55.304357: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-20 16:28:55.512705: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-20 16:28:55.606861: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-20 16:28:58.798624: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-20 16:29:00.860270: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-20 16:29:01.479918: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-20 16:29:04.057429: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-20 16:29:11.714856: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-20 16:29:12.230242: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-20 16:29:14.510829: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-20 16:29:14.652898: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-20 16:29:17.134882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-20 16:29:17.348917: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-20 16:29:17.400418: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-20 16:29:19.806726: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/utils/_response.py\", line 235, in _get_response_values\n",
      "    raise ValueError(\n",
      "ValueError: KerasClassifier should either be a classifier to be used with response_method=predict_proba or the response_method should be 'predict'. Got a regressor with response_method=predict_proba instead.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/utils/_response.py\", line 235, in _get_response_values\n",
      "    raise ValueError(\n",
      "ValueError: KerasClassifier should either be a classifier to be used with response_method=predict_proba or the response_method should be 'predict'. Got a regressor with response_method=predict_proba instead.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/utils/_response.py\", line 235, in _get_response_values\n",
      "    raise ValueError(\n",
      "ValueError: KerasClassifier should either be a classifier to be used with response_method=predict_proba or the response_method should be 'predict'. Got a regressor with response_method=predict_proba instead.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/utils/_response.py\", line 235, in _get_response_values\n",
      "    raise ValueError(\n",
      "ValueError: KerasClassifier should either be a classifier to be used with response_method=predict_proba or the response_method should be 'predict'. Got a regressor with response_method=predict_proba instead.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/utils/_response.py\", line 235, in _get_response_values\n",
      "    raise ValueError(\n",
      "ValueError: KerasClassifier should either be a classifier to be used with response_method=predict_proba or the response_method should be 'predict'. Got a regressor with response_method=predict_proba instead.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/utils/_response.py\", line 235, in _get_response_values\n",
      "    raise ValueError(\n",
      "ValueError: KerasClassifier should either be a classifier to be used with response_method=predict_proba or the response_method should be 'predict'. Got a regressor with response_method=predict_proba instead.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/utils/_response.py\", line 235, in _get_response_values\n",
      "    raise ValueError(\n",
      "ValueError: KerasClassifier should either be a classifier to be used with response_method=predict_proba or the response_method should be 'predict'. Got a regressor with response_method=predict_proba instead.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/utils/_response.py\", line 235, in _get_response_values\n",
      "    raise ValueError(\n",
      "ValueError: KerasClassifier should either be a classifier to be used with response_method=predict_proba or the response_method should be 'predict'. Got a regressor with response_method=predict_proba instead.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/utils/_response.py\", line 235, in _get_response_values\n",
      "    raise ValueError(\n",
      "ValueError: KerasClassifier should either be a classifier to be used with response_method=predict_proba or the response_method should be 'predict'. Got a regressor with response_method=predict_proba instead.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/utils/_response.py\", line 235, in _get_response_values\n",
      "    raise ValueError(\n",
      "ValueError: KerasClassifier should either be a classifier to be used with response_method=predict_proba or the response_method should be 'predict'. Got a regressor with response_method=predict_proba instead.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/utils/_response.py\", line 235, in _get_response_values\n",
      "    raise ValueError(\n",
      "ValueError: KerasClassifier should either be a classifier to be used with response_method=predict_proba or the response_method should be 'predict'. Got a regressor with response_method=predict_proba instead.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/utils/_response.py\", line 235, in _get_response_values\n",
      "    raise ValueError(\n",
      "ValueError: KerasClassifier should either be a classifier to be used with response_method=predict_proba or the response_method should be 'predict'. Got a regressor with response_method=predict_proba instead.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/utils/_response.py\", line 235, in _get_response_values\n",
      "    raise ValueError(\n",
      "ValueError: KerasClassifier should either be a classifier to be used with response_method=predict_proba or the response_method should be 'predict'. Got a regressor with response_method=predict_proba instead.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/utils/_response.py\", line 235, in _get_response_values\n",
      "    raise ValueError(\n",
      "ValueError: KerasClassifier should either be a classifier to be used with response_method=predict_proba or the response_method should be 'predict'. Got a regressor with response_method=predict_proba instead.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/utils/_response.py\", line 235, in _get_response_values\n",
      "    raise ValueError(\n",
      "ValueError: KerasClassifier should either be a classifier to be used with response_method=predict_proba or the response_method should be 'predict'. Got a regressor with response_method=predict_proba instead.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/utils/_response.py\", line 235, in _get_response_values\n",
      "    raise ValueError(\n",
      "ValueError: KerasClassifier should either be a classifier to be used with response_method=predict_proba or the response_method should be 'predict'. Got a regressor with response_method=predict_proba instead.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/utils/_response.py\", line 235, in _get_response_values\n",
      "    raise ValueError(\n",
      "ValueError: KerasClassifier should either be a classifier to be used with response_method=predict_proba or the response_method should be 'predict'. Got a regressor with response_method=predict_proba instead.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/utils/_response.py\", line 235, in _get_response_values\n",
      "    raise ValueError(\n",
      "ValueError: KerasClassifier should either be a classifier to be used with response_method=predict_proba or the response_method should be 'predict'. Got a regressor with response_method=predict_proba instead.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Function to create model\n",
    "def create_model(learning_rate=0.001, neurons=64, dropout_rate=0.2):\n",
    "    model = Sequential([\n",
    "        Dense(neurons, activation='relu', input_shape=(X_train_transformed.shape[1],)),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(neurons//2, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['AUC'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Wrap Keras model for Scikit-learn\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'learning_rate': [0.001, 0.0005, 0.0001],\n",
    "    'neurons': [64, 128],\n",
    "    'dropout_rate': [0.2, 0.3, 0.4],\n",
    "    'batch_size': [32, 64]\n",
    "}\n",
    "\n",
    "# Perform Randomized Search\n",
    "grid_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid,\n",
    "                                 n_iter=10, scoring='roc_auc', cv=3, verbose=0, n_jobs=-1)\n",
    "\n",
    "# Train the model with best parameters\n",
    "grid_search.fit(X_train_transformed, y_train_smote)\n",
    "\n",
    "# Get best model\n",
    "best_model = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     35544\n",
      "           1       0.75      0.88      0.81        57\n",
      "\n",
      "    accuracy                           1.00     35601\n",
      "   macro avg       0.87      0.94      0.90     35601\n",
      "weighted avg       1.00      1.00      1.00     35601\n",
      "\n",
      "AUC-ROC Score: 0.9383573510074985\n"
     ]
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Define the model\n",
    "brf = BalancedRandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define a reduced parameter grid\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [None, 10, 20],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Perform Randomized Search\n",
    "random_search = RandomizedSearchCV(brf, param_grid, scoring='roc_auc', cv=3, n_iter=20, n_jobs=1, verbose=1, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best model\n",
    "best_brf = random_search.best_estimator_\n",
    "\n",
    "# Make predictions\n",
    "y_pred = best_brf.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"AUC-ROC Score:\", roc_auc_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_train['Amount_log'] = np.log1p(X_train['Amount'])\n",
    "X_test['Amount_log'] = np.log1p(X_test['Amount'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution befor SMOTE in first part: Counter({0: 284315, 1: 492})\n",
      "Original class distribution after SMOTE in first part: Counter({0: 213236, 1: 63970})\n",
      "Original class distribution befor Tomek: Counter({0: 213236, 1: 63970})\n",
      "After Tomek Links: Counter({0: 213229, 1: 63970})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data1 = pd.read_csv('raw_data/creditcard.csv')\n",
    "df = data1.copy()\n",
    "\n",
    "# Remove duplicate rows\n",
    "#df = df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Extract transaction hour and apply cyclical transformation\n",
    "df['Hour'] = (df['Time'] // 3600) % 24\n",
    "# Apply cyclical transformation\n",
    "df[\"Hour_sin\"] = np.sin(2 * np.pi * df[\"Hour\"] / 24)\n",
    "df[\"Hour_cos\"] = np.cos(2 * np.pi * df[\"Hour\"] / 24)\n",
    "df.drop(columns=[\"Hour\", \"Time\"], inplace=True)\n",
    "\n",
    "# Define features and labels\n",
    "X = df.drop(\"Class\", axis=1)\n",
    "y = df[\"Class\"]\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"Original class distribution befor SMOTE in first part:\", Counter(y))\n",
    "\n",
    "# Apply BorderlineSMOTE (instead of regular SMOTE)\n",
    "smote = BorderlineSMOTE(sampling_strategy=0.3, random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Original class distribution after SMOTE in first part:\", Counter(y_train_smote))\n",
    "\n",
    "#y_train_smote= pd.DataFrame(y_train_smote)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_smote.iloc[:, 1:29] = scaler.fit_transform(X_train_smote.iloc[:, 1:29])\n",
    "X_test.iloc[:, 1:29] = scaler.transform(X_test.iloc[:, 1:29])\n",
    "X_val.iloc[:, 1:29] = scaler.transform(X_val.iloc[:, 1:29])\n",
    "\n",
    "columns_to_winsorize = [\"V8\", \"V18\", \"V21\", \"V27\", \"V28\"]\n",
    "for col in columns_to_winsorize:\n",
    "    X_train_smote[col] = winsorize(X_train_smote[col], limits=[0.01, 0.01])\n",
    "    X_test[col] = winsorize(X_test[col], limits=[0.01, 0.01])\n",
    "    X_val[col] = winsorize(X_val[col], limits=[0.01, 0.01])\n",
    "\n",
    "X_train_smote['V20'] = np.log(X_train_smote['V20'].clip(lower=0.0001))\n",
    "X_train_smote['V23'] = np.log(X_train_smote['V23'].clip(lower=0.0001))\n",
    "X_test['V20'] = np.log(X_test['V20'].clip(lower=0.0001))\n",
    "X_test['V23'] = np.log(X_test['V23'].clip(lower=0.0001))\n",
    "X_val['V20'] = np.log(X_val['V20'].clip(lower=0.0001))\n",
    "X_val['V23'] = np.log(X_val['V23'].clip(lower=0.0001))\n",
    "\n",
    "X_train_smote[\"Amount\"] = np.log1p(X_train_smote[\"Amount\"])  # log(1 + Amount) to handle zero values\n",
    "X_test[\"Amount\"] = np.log1p(X_test[\"Amount\"])  # log(1 + Amount) to handle zero values\n",
    "X_val[\"Amount\"] = np.log1p(X_val[\"Amount\"])\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_smote[\"Amount\"] = scaler.fit_transform(X_train_smote[[\"Amount\"]])\n",
    "X_test[\"Amount\"] = scaler.transform(X_test[[\"Amount\"]])\n",
    "X_val[\"Amount\"] = scaler.transform(X_val[[\"Amount\"]])\n",
    "\n",
    "X_train_smote[\"Amount\"] = winsorize(X_train_smote[\"Amount\"], limits=[0.01, 0.01])\n",
    "X_test[\"Amount\"] = winsorize(X_test[\"Amount\"], limits=[0.01, 0.01])\n",
    "X_val[\"Amount\"] = winsorize(X_val[\"Amount\"], limits=[0.01, 0.01])\n",
    "\n",
    "# Ensure all features are scaled if necessary (PCA is sensitive to feature scaling)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_smote)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "\"\"\"n_components = 24\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\"\"\"\n",
    "\n",
    "print(\"Original class distribution befor Tomek:\", Counter(y_train_smote))\n",
    "\n",
    "\n",
    "# Apply Tomek Links only if class imbalance remains\n",
    "tomek = TomekLinks()\n",
    "X_final, y_final = tomek.fit_resample(X_train_scaled, y_train_smote)\n",
    "\n",
    "# Check final class distribution\n",
    "print(\"After Tomek Links:\", Counter(y_final))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_final, columns=X.columns)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
    "X_val = pd.DataFrame(X_val_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
       "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
       "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Hour_sin',\n",
       "       'Hour_cos'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=X_train.iloc[:, 1:29])  # Excluding 'Time', 'Amount', 'Hour', 'Class'\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Boxplot of PCA Features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balanced Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     35409\n",
      "           1       0.91      0.75      0.83        57\n",
      "\n",
      "    accuracy                           1.00     35466\n",
      "   macro avg       0.96      0.88      0.91     35466\n",
      "weighted avg       1.00      1.00      1.00     35466\n",
      "\n",
      "AUC-ROC Score: 0.8771364996410369\n"
     ]
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Initialize the Balanced Random Forest model\n",
    "model = BalancedRandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"AUC-ROC Score:\", roc_auc_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     35409\n",
      "           1       0.84      0.75      0.80        57\n",
      "\n",
      "    accuracy                           1.00     35466\n",
      "   macro avg       0.92      0.88      0.90     35466\n",
      "weighted avg       1.00      1.00      1.00     35466\n",
      "\n",
      "AUC-ROC Score: 0.8770800168259334\n"
     ]
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Define the model\n",
    "brf = BalancedRandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define a reduced parameter grid\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [None, 10, 20],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Perform Randomized Search\n",
    "random_search = RandomizedSearchCV(brf, param_grid, scoring='roc_auc', cv=3, n_iter=20, n_jobs=1, verbose=1, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best model\n",
    "best_brf = random_search.best_estimator_\n",
    "\n",
    "# Make predictions\n",
    "y_pred = best_brf.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"AUC-ROC Score:\", roc_auc_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n"
     ]
    },
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {SIGKILL(-9)}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Perform Grid Search\u001b[39;00m\n\u001b[1;32m     18\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(brf, param_grid, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Get best model\u001b[39;00m\n\u001b[1;32m     22\u001b[0m best_brf \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1020\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1570\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1571\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    967\u001b[0m         )\n\u001b[1;32m    968\u001b[0m     )\n\u001b[0;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    993\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/joblib/parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1748\u001b[0m \n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[0;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/joblib/parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/joblib/parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[0;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/joblib/parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {SIGKILL(-9)}"
     ]
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees\n",
    "    'max_depth': [None, 10, 20],  # Depth of trees\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum samples at leaf node\n",
    "    'max_features': ['sqrt', 'log2']  # Number of features to consider\n",
    "}\n",
    "\n",
    "# Initialize the Balanced Random Forest model\n",
    "brf = BalancedRandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(brf, param_grid, scoring='roc_auc', cv=3, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best model\n",
    "best_brf = grid_search.best_estimator_\n",
    "y_pred_best = best_brf.predict(X_test)\n",
    "\n",
    "# Output results\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "print(\"AUC-ROC Score:\", roc_auc_score(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 20}\n",
      "Updated Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     35544\n",
      "           1       0.74      0.88      0.80        57\n",
      "\n",
      "    accuracy                           1.00     35601\n",
      "   macro avg       0.87      0.94      0.90     35601\n",
      "weighted avg       1.00      1.00      1.00     35601\n",
      "\n",
      "Updated AUC-ROC Score: 0.9383432839357002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5],\n",
    "}\n",
    "\n",
    "# Randomized search\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=10, scoring='roc_auc', cv=5, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "\n",
    "# Evaluate best model\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "print(\"Updated Classification Report:\\n\", classification_report(y_test, y_pred_best))\n",
    "print(\"Updated AUC-ROC Score:\", roc_auc_score(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     35544\n",
      "           1       0.14      0.91      0.24        57\n",
      "\n",
      "    accuracy                           0.99     35601\n",
      "   macro avg       0.57      0.95      0.62     35601\n",
      "weighted avg       1.00      0.99      0.99     35601\n",
      "\n",
      "AUC-ROC Score: 0.9514841501119442\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train Logistic Regression model\n",
    "log_model = LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced')\n",
    "log_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = log_model.predict(X_test)\n",
    "\n",
    "# Evaluate Model Performance\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"AUC-ROC Score:\", roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     35544\n",
      "           1       0.14      0.91      0.24        57\n",
      "\n",
      "    accuracy                           0.99     35601\n",
      "   macro avg       0.57      0.95      0.62     35601\n",
      "weighted avg       1.00      0.99      0.99     35601\n",
      "\n",
      "AUC-ROC Score: 0.9514841501119442\n"
     ]
    }
   ],
   "source": [
    "log_model_l1 = LogisticRegression(penalty='l1', solver='liblinear', random_state=42, max_iter=1000, class_weight='balanced')\n",
    "log_model_l1.fit(X_train, y_train)\n",
    "# Make predictions\n",
    "y_pred = log_model.predict(X_test)\n",
    "\n",
    "# Evaluate Model Performance\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"AUC-ROC Score:\", roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best Parameters: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     35544\n",
      "           1       0.14      0.91      0.24        57\n",
      "\n",
      "    accuracy                           0.99     35601\n",
      "   macro avg       0.57      0.95      0.62     35601\n",
      "weighted avg       1.00      0.99      0.99     35601\n",
      "\n",
      "AUC-ROC Score: 0.9514560159683475\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "    'penalty': ['l1', 'l2'],  # L1 for feature selection, L2 for stability\n",
    "    'solver': ['liblinear', 'saga']  # 'liblinear' for small datasets, 'saga' for large\n",
    "}\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "log_model = LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000)\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(log_model, param_grid, scoring='recall', cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Evaluate the best model\n",
    "best_log_model = grid_search.best_estimator_\n",
    "y_pred = best_log_model.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"AUC-ROC Score:\", roc_auc_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (Adjusted Threshold):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     35544\n",
      "           1       0.07      0.91      0.13        57\n",
      "\n",
      "    accuracy                           0.98     35601\n",
      "   macro avg       0.53      0.95      0.56     35601\n",
      "weighted avg       1.00      0.98      0.99     35601\n",
      "\n",
      "AUC-ROC Score (Adjusted Threshold): 0.9463918701209472\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAG2CAYAAACtaYbcAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAR2lJREFUeJzt3XlcVPX+x/H3gDCIsrixqLjnvuVGpOa1KG2xvP0qW67bzbyVVldui2Zlq1S3vFZalmV6K1Mz63bTtMS8llqmRou5i0kl4JKgoCBwfn98A0RRGYQ5zMzr+XjMY2bOnJn5zKl7efddHZZlWQIAALCJn90FAAAA30YYAQAAtiKMAAAAWxFGAACArQgjAADAVoQRAABgK8IIAACwFWEEAADYijACAABsRRgBAAC2cjmMrFq1SoMGDVLDhg3lcDj04YcfnvU9K1euVLdu3eR0OtWqVSvNnj27AqUCAABv5HIYyc7OVpcuXTR9+vRynZ+SkqIrr7xS/fv3V3Jysv7+979r1KhRWrZsmcvFAgAA7+M4l43yHA6HPvjgAw0ePPi05zzwwANavHixfvzxx+JjN954ow4dOqSlS5dW9KsBAICXqFHVX7B27VrFx8eXOjZgwAD9/e9/P+17cnNzlZubW/y8sLBQBw8eVL169eRwOKqqVAAAUIksy9Lhw4fVsGFD+fmdvjOmysNIWlqaIiMjSx2LjIxUVlaWjh49qpo1a57ynsTERD322GNVXRoAAHCD1NRUNW7c+LSvV3kYqYgJEyYoISGh+HlmZqaaNGmi1NRUhYaGVtr37P59t44VHJMkZRzJ0KB3B8nfz18HHzhYad8BAICvysrKUkxMjEJCQs54XpWHkaioKKWnp5c6lp6ertDQ0DJbRSTJ6XTK6XSecjw0NLRSw0jn0M4lNR1Jl4KkAhUoJCSE7iAAACrJ2f6mVvk6I3FxcUpKSip17LPPPlNcXFxVf7VLAvwDih8XWAU2VgIAgG9xOYwcOXJEycnJSk5OlmSm7iYnJ2vPnj2STBfLsGHDis+//fbbtWvXLt1///3asmWLXn75ZS1YsEDjxo2rnF9QSWr4lTQS5Rfm21gJAAC+xeVumvXr16t///7Fz4vGdgwfPlyzZ8/W3r17i4OJJDVv3lyLFy/WuHHj9MILL6hx48Z6/fXXNWDAgEoov/KcGEZe/PpFOf1P7SY6Uau6rXRl6yuruiwAALzeOa0z4i5ZWVkKCwtTZmZmpY4ZOVF+Yb6CnwrW8cLj5X7PljFb1KZ+myqpBwAAT1fev9/VcjaNHWr41dBrg17Tpzs/Peu5H2/7WIfzDmtfzj61EWEEAIBzQRg5wYiuIzSi64izntfh5Q76ad9POl5Q/lYUAABQNnbtrYCi8SUMdAUA4NwRRiogwM9MAyaMAABw7ggjFUDLCAAAlYcxIxVQtEDa9e9dX2qxtLNpGtZUq0auUt2adauqNAAAPA4tIxXQs2FPSVJuQa6O5B0p923Tvk1a9+s6m6sHAKB6oWWkAp6/7Hn9/YK/u9RNc+38a/Vd+nfMwAEA4CSEkQpwOBxqEtbEpffUDqwtiXEmAACcjG4aNyka9OrKCq8AAPgCwoibFA10pZsGAIDS6KZxk6K1ST7c+qFSs1JtrqZsA1sNVNeornaXAQDwMYQRNwl1mg2CFv60UAt/WmhzNWWbuXGmdt690+4yAAA+hjDiJg9d9JDCg8KVV5BndymnyD6erQWbFmjv4b12lwIA8EGEETfpGNFRM66aYXcZZcrIztCCTQt0NP+oCq1C+TkYSgQAcB/+6kC1AmoVPz56/KiNlQAAfBFhBKoZULP4cc7xHBsrAQD4IsII5OfwU80aJpAQRgAA7saYEUiSggOCdTT/qFq82EIOOarse/o27aukYUmMSwEAFOMvAiRJ/Zr1kyQVWoUqsAqq7LZy90rty95n868FAFQntIxAkrTw+oVKO5ImS1aVfUeTfzUpDiUAABQhjECS2fwvOiS6Sr/D389fBQUFKigkjAAAStBNA7cp2iyQnYsBACcijMBt/B3+kkQ3DQCgFLpp4DZFLSNTv5qq+sH1ba4G8HwhgSG6tdutCg8Kt7sU4JwQRuA2Ic4Q/X7sd03/ZrrdpQBeI68gTxP6TrC7DOCcEEbgNm9c/YYWbV5kdxmAV/j616+1ce9GZWRn2F0KcM4II3Cb+Bbxim8Rb3cZgFd44n9PaOPejayaDK/AAFYA8EBFe0rl5BNG4PkIIwDggYIDgiWx0za8A2EEADxQ0eaWR/KOsHYPPB5hBAA8UFHLyLKdyxTwRICGfTDM5oqAiiOMAIAH6tmop0KdocXPF2xaIMuqur2lgKpEGAEAD9SiTgtl3Juh3xJ+kyTlFuQqMzfT5qqAiiGMAICHctZwKjokWmHOMEnS3sN7ba4IqBjCCAB4uKIdt9OOpNlcCVAxhBEA8HBRtaMkSXuP0DICz8QKrADg4aJrm5aRN5Pf1Pfp39tcjfuEOkN1V6+7FOIMsbsUnCPCCAB4uObhzSVJy3ct1/Jdy22uxv0e7Pug3SXgHBFGAMDD3XPBPfL389eRvCN2l+I2W/Zv0Sc7PtGKlBWEES9AGAEADxdRK0KP93/c7jLcalPGJn2y4xOtSV2jvII8BfoH2l0SzgEDWAEAHqddg3aqV7OejuYf1frf1ttdDs4RYQQA4HH8HH66qOlFkqT/7f6fzdXgXNFNAwDwSP2a9tMHWz7Q57s/112xd9ldTrVSK6CWHA6H3WWUG2EEAOCR+jXrJ0n6bNdnCklkeu+JYhvFas2ta+Tn8IwOEM+oEgCAk3SO7KzYRrF2l1Etff3r19p9aLfdZZQbLSMAAI/k5/DT2lvX6mj+UbtLqVZ6z+qt5LRkfZ/+vVrUaWF3OeVCGAEAeCyHw6HggGC7y6hWukZ1LQ4jg9sOPuv5zz0nLV8u/ec/ktNZ9fWVhW4aAAC8SOeIzpJU7q0B7rtPWrZMmjOnKqs6M8IIAABepHOka2HE39/ct25dVRWdHd00AAB4kaIwsuPgDt3zyT1yOBzqGtVVI7qOKPP8pk2lXbukoCA3FnkSwggAAF6kQa0GigmNUWpWql5c92Lx8e7R3dUpspONlZ0e3TQAAHiZ965/Tw/2eVAT+kwobilZtHlRmefu2mXu9+xxV3WnomUEAAAvE9s4VrGNzRosbeq10Yj/jNCiLYs06U+TTvue335zV3WnomUEAAAvNqjNIPk7/PV9+vfacXDHac8LCHBjUSchjAAA4MXq1qyr/s37Syq7q6bFH+uide/uzqpKI4wAAODl/q/d/0mSFv60UPtz9pe6FQZk2Vyd5LAsy7K7iLPJyspSWFiYMjMzFRoaanc5AAB4lL2H96rRlEayVMaffMshffS61r78V11wQeV+b3n/ftMyAgCAl4sOiT7tOiNyWFKL5dq0ya0llcJsGgAAfMCsa2bp9atfL3Vs7g9zNfSDoVKtdB0+bFNhIowAAOAz/BylO0SiakeZB7Uy1MnG9dDopgEAwEdF1IowD2plqFYt++ogjAAA4KOKw0jwfhVYBbbVUaEwMn36dDVr1kxBQUGKjY3VunXrznj+1KlT1aZNG9WsWVMxMTEaN26cjh07VqGCAQBA5agfXN/MpvEr1JafD9hWh8thZP78+UpISNCkSZO0ceNGdenSRQMGDFBGRkaZ58+dO1fjx4/XpEmTtHnzZr3xxhuaP3++HnzwwXMuHgAAVFwNvxpmNo2kH39Jsa0Ol8PIlClTdNttt2nkyJFq3769ZsyYoeDgYM2aNavM89esWaPevXvr5ptvVrNmzXTZZZfppptuOmtrCgAAcJ9One37bpfCSF5enjZs2KD4+PiSD/DzU3x8vNauXVvmey688EJt2LChOHzs2rVLS5Ys0RVXXHHa78nNzVVWVlapGwAAqHzNw5tLkjq0t68Gl6b27t+/XwUFBYqMjCx1PDIyUlu2bCnzPTfffLP279+vPn36yLIs5efn6/bbbz9jN01iYqIee+wxV0oDAAAeqspn06xcuVKTJ0/Wyy+/rI0bN2rRokVavHixnnjiidO+Z8KECcrMzCy+paamVnWZAADAJi61jNSvX1/+/v5KT08vdTw9PV1RUVFlvufhhx/W0KFDNWrUKElSp06dlJ2drdGjR2vixIny8zs1DzmdTjmdTldKAwAAFbBvn6QAKWW3FNvYnhpcahkJDAxU9+7dlZSUVHyssLBQSUlJiouLK/M9OTk5pwQOf39/SZIH7NEHAIBXK1ppI/uIfTW4vBx8QkKChg8frh49eqhXr16aOnWqsrOzNXLkSEnSsGHD1KhRIyUmJkqSBg0apClTpuj8889XbGysduzYoYcffliDBg0qDiUAAMB3uRxGhgwZon379umRRx5RWlqaunbtqqVLlxYPat2zZ0+plpCHHnpIDodDDz30kH799Vc1aNBAgwYN0lNPPVV5vwIAAHgsh+UBfSVZWVkKCwtTZmamQkND7S4HAACvEXBvC+WHpOj12K9068DYSv3s8v79Zm8aAABgK8IIAACwFWEEAADYijACAIAPi4kx9x072lcDYQQAAB+Wk2PuC22czkIYAQDAhxUtqr5ypX01EEYAAIC2bLbvuwkjAABAffra992EEQAAfFjRziyBgfbVQBgBAADyc9j43fZ9NQAAqC4chBEAAGCHRo3MfbNm9tVAGAEAwIcVjRkJCLCvBsIIAACwFWEEAAAf9vvv5v7gQftqIIwAAODDsrLM/eEj9tVAGAEAwIcVbUlj42QawggAAD7tjzTisDEREEYAAACLngEAAHux6BkAALAV3TQAAMAWVtGYEVpGAACAHRo3Nvf169lXA2EEAAAfVrQMfI0a9tVAGAEAALYijAAA4MOKloPPOWpfDYQRAAB8lGVJhw6Zx7m59tVBGAEAwEcVzaSRWPQMAADYIDPzhCeEEQAA4G5vvVXy2I9FzwAAgLt16FDymF17AQCA2/XtW9IiUjPYvjoIIwAA+KCCAjOAtUkT89yfbhoAAOBO8+dLtWpJ6el2V0IYAQDA51iW9M9/mtaRoCC7qyGMAADgc5Yvl5KTpeBgKTTU7moIIwAA+JSCAunxx83jUaPsndJbpBqUAAAA3OWZZ6QvvzStIgkJdldjEEYAAPARa9ZIjzxiHk+fLjVtam89RWrYXQAAAHCPggIpIkK6+GJp+HC7qylBGAEAwEf07St9953kdEoOO5dcPQlhBAAAH9Kggd0VnIoxIwAA+IBNm6Q9e6T8fLsrORVhBAAAH3DjjWbA6ooVdldyKrppAADwYikpUlaWdOiQeV6vnq3llIkwAgCAl7IsacAAafv2ksXN/P3traksdNMAAOClHA5p1izzuLDQ3FeHFVdPVg1LAgAAlaVPH+mFF0pCSFiYvfWUhW4aAAC83N13Sz17Sr/+Wn1WXT0RYQQAAC9kWVK/flKbNtLkyVJcnN0VnR7dNAAAeKGdO6UvvpD+/W8pJMTuas6MMAIAgBf64gtz37OnFBRkby1nQxgBAMALvfOOub/4YnvrKA/CCAAAXmbzZikpycygufVWu6s5O8IIAABeZvp0c3/11dVz9szJCCMAAHiZVavM/fDh9tZRXkztBQDAy/zpT1Lz5lLLlnZXUj6EEQAAvMyLL9pdgWvopgEAALYijAAAAFsRRgAA8DJNm0pOp5ScbHcl5cOYEQAAvMhLL0l79pjHfh7S5OAhZQIAgLM5fNjs0Fukhoc0OVQojEyfPl3NmjVTUFCQYmNjtW7dujOef+jQIY0ZM0bR0dFyOp1q3bq1lixZUqGCAQBA2QoKSj/397enDle5nJnmz5+vhIQEzZgxQ7GxsZo6daoGDBigrVu3KiIi4pTz8/LydOmllyoiIkILFy5Uo0aN9PPPPys8PLwy6gcAAH8ID5eys6UOHaRDh6RGjeyuqHxcDiNTpkzRbbfdppEjR0qSZsyYocWLF2vWrFkaP378KefPmjVLBw8e1Jo1axQQECBJatas2blVDQAASikoMC0hwcHSpk3mee3adldVPi510+Tl5WnDhg2Kj48v+QA/P8XHx2vt2rVlvuejjz5SXFycxowZo8jISHXs2FGTJ09WwcltSSfIzc1VVlZWqRsAACjb8ePSoEFSYqJkWSaQhITYXVX5uRRG9u/fr4KCAkVGRpY6HhkZqbS0tDLfs2vXLi1cuFAFBQVasmSJHn74YT3//PN68sknT/s9iYmJCgsLK77FxMS4UiYAAD7l8celTz6RnnxS+vlnu6txXZXPpiksLFRERIRee+01de/eXUOGDNHEiRM1Y8aM075nwoQJyszMLL6lpqZWdZkAAHiko0ell182j19/XfLEkRAujRmpX7++/P39lZ6eXup4enq6oqKiynxPdHS0AgIC5H/CkN527dopLS1NeXl5CgwMPOU9TqdTTqfTldIAAPBJCxZIBw9KTZpIN9xgdzUV41LLSGBgoLp3766kpKTiY4WFhUpKSlJcXFyZ7+ndu7d27NihwsLC4mPbtm1TdHR0mUEEAACU36JF5v622zxnKu/JXO6mSUhI0MyZMzVnzhxt3rxZd9xxh7Kzs4tn1wwbNkwTJkwoPv+OO+7QwYMHdc8992jbtm1avHixJk+erDFjxlTerwAAwEft22fuO3Swt45z4fLU3iFDhmjfvn165JFHlJaWpq5du2rp0qXFg1r37NkjvxPWn42JidGyZcs0btw4de7cWY0aNdI999yjBx54oPJ+BQAAPur33819nTr21nEuKrRQ7NixYzV27NgyX1u5cuUpx+Li4vTVV19V5KsAAMAZ3HyztHq11Lix3ZVUnIesWg8AAMry8MN2V3Du2CgPAAAPVFAg5eXZXUXlIIwAAOBhCgqkkSOl666TcnPtrubc0U0DAICHmTBBeustM5X366+liy6yu6JzQ8sIAAAepmhtkVde8fwgIhFGAADwOMeOmfvu3e2to7J4TTdNYWGh8rxlJI+POHmbAABA+Rw5Yu6Dg+2to7J4RRjJy8tTSkpKqSXn4RnCw8MVFRUlh8NhdykA4BEOHJAyM83jJk3sraWyeHwYsSxLe/fulb+/v2JiYkqt/orqy7Is5eTkKCMjQ5LZUBEAcHZbt5r7mBhaRqqN/Px85eTkqGHDhgr2ln8qPqJmzZqSpIyMDEVERNBlAwDlEBEh3Xef5E0Nyh4fRgoKCiSJHYA9VFGAPH78OGEEAMqhVSvp2WftrqJyeU2fBmMOPBP/3ACgfD76SHrhBburqBoe3zICAIA3279f+utfpf/+VwoIkAYOlNq0sbuqyuU1LSM4O4fDoQ8//LDSzwUAVA3LKh1E7r3Xs3fnPR3CiE1GjBghh8Mhh8OhwMBAtWrVSo8//rjy8/Or7Dv37t2ryy+/vNLPBQBUjQULSoLImjXS5MlSrVp2V1X56Kax0cCBA/Xmm28qNzdXS5Ys0ZgxYxQQEKAJEyaUOi8vL69SBuhGRUVVybkAgMqXmyuNG2ceT5wo9ehhbz1ViZYRGzmdTkVFRalp06a64447FB8fr48++kgjRozQ4MGD9dRTT6lhw4Zq80fnYGpqqm644QaFh4erbt26uuaaa7R79+5Snzlr1ix16NBBTqdT0dHRGjt2bPFrJ3a95OXlaezYsYqOjlZQUJCaNm2qxMTEMs+VpB9++EEXX3yxatasqXr16mn06NE6UrQEoFRc83PPPafo6GjVq1dPY8aM0fHjxyv/wgGAD3j3XWnvXqlRI2n8eLurqVpe2zKSnX361/z9paCg8p3r5yf9sRzGGc+tjGazmjVr6sCBA5KkpKQkhYaG6rPPPpNkpr4OGDBAcXFx+uKLL1SjRg09+eSTGjhwoL7//nsFBgbqlVdeUUJCgp5++mldfvnlyszM1OrVq8v8rhdffFEfffSRFixYoCZNmig1NVWpqallnpudnV383d98840yMjI0atQojR07VrNnzy4+7/PPP1d0dLQ+//xz7dixQ0OGDFHXrl112223nfvFAQAfc/Cg+dty992S02l3NVXLa8NI7dqnf+2KK6TFi0ueR0RIOTlln9uvn7RyZcnzZs3MyOaTWVZFqix6r6WkpCQtW7ZMd911l/bt26datWrp9ddfL+6eefvtt1VYWKjXX3+9eDrsm2++qfDwcK1cuVKXXXaZnnzySf3jH//QPffcU/zZPXv2LPM79+zZo/POO099+vSRw+FQ06ZNT1vf3LlzdezYMf373/9WrT9S17Rp0zRo0CA988wzioyMlCTVqVNH06ZNk7+/v9q2basrr7xSSUlJhBEAqICEBDN41ReWYKKbxkYff/yxateuraCgIF1++eUaMmSIHn30UUlSp06dSo0T+e6777Rjxw6FhISodu3aql27turWratjx45p586dysjI0G+//aZLLrmkXN89YsQIJScnq02bNrr77rv16aefnvbczZs3q0uXLsVBRJJ69+6twsJCbS1al1hShw4dSi1cFh0dXbzcOwDAdeHhUkiI3VVUPa9tGTlhOMMpTk6ZZ/p7efJWNycN0Tgn/fv31yuvvKLAwEA1bNhQNWqU/OOodVK/z5EjR9S9e3e98847p3xOgwYNXN6Tp1u3bkpJSdEnn3yi5cuX64YbblB8fLwWLlxYsR8jswvviRwOB5sXAgDOymvDiCtjOKrq3LN/Vi21atWqXOd269ZN8+fPV0REhEJDQ8s8p1mzZkpKSlL//v3L9ZmhoaEaMmSIhgwZouuuu04DBw7UwYMHVbdu3VLntWvXTrNnz1Z2dnZxSFq9erX8/PyKB9cCACrPv/5lbjffLD39tN3VVD26aTzELbfcovr16+uaa67RF198oZSUFK1cuVJ33323fvnlF0nSo48+queff14vvviitm/fro0bN+qll14q8/OmTJmid999V1u2bNG2bdv03nvvKSoqSuHh4WV+d1BQkIYPH64ff/xRn3/+ue666y4NHTq0eLwIAKByWJb09ttSaqp0mv/29DqEEQ8RHBysVatWqUmTJrr22mvVrl073XrrrTp27FhxS8nw4cM1depUvfzyy+rQoYOuuuoqbd++vczPCwkJ0bPPPqsePXqoZ8+e2r17t5YsWVJmd09wcLCWLVumgwcPqmfPnrruuut0ySWXaNq0aVX6mwHAFyUlSRs3mpmco0fbXY17OCzrXOaBuEdWVpbCwsKUmZl5ShfFsWPHlJKSoubNmyvoxPm68Aj88wOA0i69VFq+XLrrLunFF6v++1q80EIph1L01a1fKbZxbKV+9pn+fp+IlhEAAKqJ774zQcTf30zt9RWEEQAAqolvvjH3F19s1rXyFV47mwYAAE/VqJH7vqtv0746r955CnXaN1qWMAIAQDUxapTpqrngAvd955zBc9z3ZadBGAEAoBp54YVTF9z0dj72cwEAqF4sS5oyRVq6VMrL870gItEyAgCArb75RvrHP8wMmjNtZeLNfDB/AQBQPRw9Ko0YYR5ff73kq8stEUYAALCBZZkBq5s3S1FR0ml27/AJhBEf5nA49OGHH0qSdu/eLYfDoeTkZFtrAgBf8eST0ty5Uo0a0jvvSPXr212RfQgjNhkxYoQcDoccDocCAgLUvHlz3X///Tp27JjdpQEAqlhqqvT44+bxK6+YRc58GQNYbTRw4EC9+eabOn78uDZs2KDhw4fL4XDomWeesbs0AEAVeustKT9f6t/fdNX4OlpGbOR0OhUVFaWYmBgNHjxY8fHx+uyzzyRJhYWFSkxMVPPmzVWzZk116dJFCxcuLPX+TZs26aqrrlJoaKhCQkLUt29f7dy5U5L0zTff6NJLL1X9+vUVFhamfv36aePGjW7/jQCAU40fL330kfTUU3ZXUj14XcuIZVnKOZ5jy3cHBwTL4XBU6L0//vij1qxZo6ZNm0qSEhMT9fbbb2vGjBk677zztGrVKv3lL39RgwYN1K9fP/3666+66KKL9Kc//UkrVqxQaGioVq9erfz8fEnS4cOHNXz4cL300kuyLEvPP/+8rrjiCm3fvl0hISGV9psBAK7z85MGDbK7iurD68JIzvEc1U6sbct3H5lwRLUCa5X7/I8//li1a9dWfn6+cnNz5efnp2nTpik3N1eTJ0/W8uXLFRcXJ0lq0aKFvvzyS7366qvq16+fpk+frrCwMM2bN08BAQGSpNatWxd/9sUndUC+9tprCg8P1//+9z9dddVVlfBrAQCoHF4XRjxJ//799corryg7O1v/+te/VKNGDf3f//2fNm3apJycHF166aWlzs/Ly9P5558vSUpOTlbfvn2Lg8jJ0tPT9dBDD2nlypXKyMhQQUGBcnJytGfPnir/XQCA05s1S1qxQrrmGrO2CLwwjAQHBOvIBHuWsAsOCHbp/Fq1aqlVq1aSpFmzZqlLly5644031LFjR0nS4sWL1eikrRudTqckqWbNmmf87OHDh+vAgQN64YUX1LRpUzmdTsXFxSkvL8+lGgEAlWv2bOmLL6ST/nvTp3ldGHE4HC51lVQXfn5+evDBB5WQkKBt27bJ6XRqz5496tevX5nnd+7cWXPmzNHx48fLbB1ZvXq1Xn75ZV1xxRWSpNTUVO3fv79KfwMA4Oy2bjX3nTvbW0d1wmyaauT666+Xv7+/Xn31Vd17770aN26c5syZo507d2rjxo166aWXNGeO2ep57NixysrK0o033qj169dr+/bteuutt7T1j3/LzzvvPL311lvavHmzvv76a91yyy1nbU0BAFSt48elov8ujIqyt5bqxOtaRjxZjRo1NHbsWD377LNKSUlRgwYNlJiYqF27dik8PFzdunXTgw8+KEmqV6+eVqxYofvuu0/9+vWTv7+/unbtqt69e0uS3njjDY0ePVrdunVTTEyMJk+erHvvvdfOnwcAPm/FCqmw0Ky2GhlpdzXVh8OyLMvuIs4mKytLYWFhyszMVGhoaKnXjh07ppSUFDVv3lxBvrrDkAfjnx8AX5CfLz38sDRlipSXJw0bJv3R0O3VzvT3+0R00wAAUMX8/aX1600QGThQevZZuyuqXuimAQCgijkcZlfebdvMYmcVXB/TaxFGAABwg7ZtzQ2nIowAAFCFVqww9716SbXtWSC82vOaMSMeMA4XZeCfGwBvlp0t3XSTdMkl0n/+Y3c11ZfHhxF/f39JYmVRD5WTYzY1PN2y9gDgyd59V8rIkJo3l264we5qqi+P76apUaOGgoODtW/fPgUEBMjPz+PzlU+wLEs5OTnKyMhQeHh4cagEAG8yb565Hz1a4r+5Ts/jw4jD4VB0dLRSUlL0888/210OXBQeHq4oliEE4IVSU0vGi9AqcmYeH0YkKTAwUOeddx5dNR4mICCAFhEAXuvf/5YsS+rXT2rRwu5qqjevCCOS2WiOFTwBANXF22+b+5Ej7a3DEzDAAgCASnbsmHTokHl81VW2luIRvKZlBACA6iIoSNq7VzpwQKpXz+5qqj9aRgAAqCIEkfIhjAAAUIm2b5fuu08qLLS7Es9BGAEAoJK8+qrUsaP03HPSnDl2V+M5GDMCAEAlWL5cuvNO0yIyYIDUp4/dFXkOwggAAJXgscdMEBk5UnrjDcnhsLsiz1Ghbprp06erWbNmCgoKUmxsrNatW1eu982bN08Oh0ODBw+uyNcCAFAtff219O235vGddxJEXOVyGJk/f74SEhI0adIkbdy4UV26dNGAAQOUkZFxxvft3r1b9957r/r27VvhYgEAqG6++EL605/MDr09e0pdu9pdkedxOYxMmTJFt912m0aOHKn27dtrxowZCg4O1qxZs077noKCAt1yyy167LHH1II1cQEAXuT886V27aQrrzR70dRgAITLXAojeXl52rBhg+Lj40s+wM9P8fHxWrt27Wnf9/jjjysiIkK33nprub4nNzdXWVlZpW4AAFQXubklj2vXlj77TPrwQ/MYrnMpjOzfv18FBQWKjIwsdTwyMlJpaWllvufLL7/UG2+8oZkzZ5b7exITExUWFlZ8i4mJcaVMAACqTGam1Lu3lJhYcqxePVpEzkWVrjNy+PBhDR06VDNnzlT9+vXL/b4JEyYoMzOz+JaamlqFVQIAUH4vvCBt2CBNmSLt22d3Nd7BpRxXv359+fv7Kz09vdTx9PR0RUVFnXL+zp07tXv3bg0aNKj4WOEfS9LVqFFDW7duVcuWLU95n9PplNPpdKU0AADcoui/j+++W2rQwN5avIVLLSOBgYHq3r27kpKSio8VFhYqKSlJcXFxp5zftm1b/fDDD0pOTi6+XX311erfv7+Sk5PpfgEAeJyjR819cLC9dXgTl3u4EhISNHz4cPXo0UO9evXS1KlTlZ2drZEjR0qShg0bpkaNGikxMVFBQUHq2LFjqfeHh4dL0inHAQDwBN9/b+6bNrW3Dm/ichgZMmSI9u3bp0ceeURpaWnq2rWrli5dWjyodc+ePfLzY8sbAID32bpV+uEH8/j88+2txZs4LMuy7C7ibLKyshQWFqbMzEyFhobaXQ4AwEf9/e9mAGvNmlJGBlN5z6a8f79pwgAAoJwmTJCuu0766iuCSGViVjQAAOUUGSm9957dVXgfwggAAGfx7bfSsWNSmzZS3bp2V+N96KYBAOAsJkyQLrxQev99uyvxToQRAADOYtMmc9+hg711eCvCCAAAZ3HkiLmvV8/eOrwVYQQAgDPIy5Oys81jVl2tGoQRAADO4KuvpOPHpYgIqXFju6vxToQRAABOIyVF+utfzeNLLpEcDnvr8VaEEQAATmP5crMxXpMm0hNP2F2N92I5eAAAzsCyzADWkBC7K/E8LAcPAMA5KPpPdYeDIFLVCCMAAJxk2zbpooukAwfsrsQ3EEYAADjBli3S5ZdLX34pPfSQ3dX4BvamAQDgD5s3SxdcIGVlSc2aSY8+andFvoGWEQAA/vCPf5ggEhtr1heJjLS7It9AGAEAQNLu3dKyZebxE08QRNyJMAIAgKQpU6TCQqldO6lfP7ur8S2EEQAA/lCjhnTvvVJgoN2V+BYWPQMA4A+HDplAUru23ZV4h/L+/WY2DQAAfwgPt7sC30Q3DQDAZ+XnS2PGSJ9/bnclvo0wAgDwSYWF0o03Si+/LA0cKO3da3dFvoswAgDwSTNmSO+/Lzmd0rx5UnS03RX5LsIIAMDnbNgg3X+/efzMM9Kf/2xvPb6OMAIA8DnPPSdlZ5ul3++4w+5qQBgBAPiUggKz1LtkNsJjTRH7EUYAAD5l507p99/NNN4+feyuBhLrjAAAfEzr1tLKlWYvmrAwu6uBRBgBAPigrl3NDdUD3TQAAJ/wxBPSwoVS9d8ExfcQRgAAXu/oUWnmTOn666XFi+2uBicjjAAAvJplSbffLqWmShER0oUX2l0RTkYYAQB4taQk6d//lvz8pHfflerWtbsinIwwAgDwWtu3m/1nJGn4cOnii+2tB2UjjAAAvNZTT0kHDkht20ovvGB3NTgdwggAwCvl5Jj1RCQpMVEKCbG1HJwBYQQA4HH275cWLDCzZIqkpZnw8ckn5nlwsPTNN9KUKdI119hSJsrJYVnVf8Z1VlaWwsLClJmZqdDQULvLAQDY7PffpZYtpchIs6T7qlXStm3mtdatpa1b7a0PRnn/frMCKwDA4wQFSa1amZaPLVvMMT8/qXlzqV07M53X4bC3RpQf3TQAAI+wa5fZZVeSataUXntNio6WGjaU5s6VDh6UduyQPvyQIOJpaBkBAFRrhYXSxo3S3/5m7vv0kQYONHvL7N4tFRSYcALPRRgBAFRLv/5qpub+5z/Sb7+ZYw6HVKtWyTmBgfbUhspFGAEAVDtZWVKvXiUhpFYtacAAafRoqW9fe2tD5SOMAACqnc2bpb17pYAAMwbk4ovNoFV4J8IIAKBaOHrUzIIJDpZiY6XHH5fy8qQrrrC7MlQ1ZtMAAGxVUCB9/LGZGfPeeyXHH3xQeuwx++qC+xBGAAC2uvtuadAgKTNTmj3btI5IZt0Qpuj6BsIIAMAWR49KU6dKL79sng8aJL3yCgHEFzFmBADgduPHS88/L+Xnm+d9+0rvv28GrML30DICAHC7WrVMEAkIkO66S/rsM4KIL6NlBADgdg8/bDa6u+kmumVAywgAwA0OHpRGjJC2by85dvPNBBEYhBEAQJV5+23pggvMtN05c6TLLzdTeYET0U0DAKh0O3ZI06ZJL7xQcuy880w48fe3ry5UT4QRAEClysmRLrrILOdeZMsWqXVrumVQNsIIAMBle/ZIP/8sHTpUcuva1UzRTU2VIiKkY8ek6dOlyy6T6tWzt15Ub4QRAEC5WZZ0++3Sa6+d+tq995ow0qaNlJxsdt4NDXV7ifBAhBEAQLk98URJEGnVSqpbVwoPN7dOnUqfSxBBeRFGAADl5vfHHMxnnpHuv9/eWuA9CCMAgDMqLCwJIRMmSE2bSn/5i701wbuwzggAoEzZ2WYPmbZtzYBVyUzLHTqUWTGoXLSMAACKWZb0+efSokXShx9Kv/5qjj/yiDR7tp2VwZtVqGVk+vTpatasmYKCghQbG6t169ad9tyZM2eqb9++qlOnjurUqaP4+Pgzng8AsMdDD0k9ekiXXGKm5P76q1k59b33pJkz7a4O3szlMDJ//nwlJCRo0qRJ2rhxo7p06aIBAwYoIyOjzPNXrlypm266SZ9//rnWrl2rmJgYXXbZZfq1KG4DAKqF99+XNm6UgoOlUaOkjz4yK6ledx076qJqOSzLslx5Q2xsrHr27Klp06ZJkgoLCxUTE6O77rpL48ePP+v7CwoKVKdOHU2bNk3Dhg0r13dmZWUpLCxMmZmZCmWuGACcs9RU6bbbpMmTpW7dzLGZM6X8fBM+GjSwtz54h/L+/XZpzEheXp42bNigCRMmFB/z8/NTfHy81q5dW67PyMnJ0fHjx1W3bt3TnpObm6vc3Nzi51lZWa6UCQAoQ2GhtHOn9OKL0ssvm+d160pz55rXb7vN3vrgu1zqptm/f78KCgoUGRlZ6nhkZKTS0tLK9RkPPPCAGjZsqPj4+NOek5iYqLCwsOJbTEyMK2UCAE5w+LAZfNq0qdkfZto0E0RatJAmTbK7OsDNU3uffvppzZs3Tx988IGCgoJOe96ECROUmZlZfEtNTXVjlQDgOQ4cMN0sN91kZsIcPy798ovZrK7IqlXSyJHmuGTOf+wxMx6kTRt76gZO5FI3Tf369eXv76/09PRSx9PT0xUVFXXG9z733HN6+umntXz5cnXu3PmM5zqdTjmdTldKAwCvl5Ehffqp5HRK118vFRSY3XF/+kn69ltpyRKzH4wk/fOfZq8YSWreXIqJkfr0kR5+WGrXzr7fAJTFpZaRwMBAde/eXUlJScXHCgsLlZSUpLi4uNO+79lnn9UTTzyhpUuXqkePHhWvFgB8UEGBWfcjMtIsODZqlJmCe/CgVKdOyXlFQcThMKGlSPv2ZtGyuXMJIqieXF70LCEhQcOHD1ePHj3Uq1cvTZ06VdnZ2Ro5cqQkadiwYWrUqJESExMlSc8884weeeQRzZ07V82aNSseW1K7dm3Vrl27En8KAHiX//xHWrtWevNN0ypS5LbbpCuvNDNe/vlPM/YjLc20mNSvbwKKv799dQOucjmMDBkyRPv27dMjjzyitLQ0de3aVUuXLi0e1Lpnzx75+ZU0uLzyyivKy8vTddddV+pzJk2apEcfffTcqgcAD3fsmLRli2m1WLjQzHYpWmp91iyz1odkAsaVV0rPPmsWIitS1Ch90rwCwKO4vM6IHVhnBIC3sCwpM9OM8Xj/fentt83zInPmSEVLML30kvTDD9Kf/mTGiLDwGDxNlawzAgA4N9u3lz2DpVcv6c9/li67rOTYXXe5ry7AToQRAKgCR45Iy5dL69ZJP/8svfOOOd6okbmPipIGDJCuvlq65hrGeMC3EUYAoBIUFkq//y599pn02mvSl1+aNT+K/OtfUkSEVKuWWQOkZk37agWqG8IIALiosNC0erRqZWaySNIbb0ijR5c+r2VL6eKLpfPPlwIDS44TRIDS3LoCKwB4ul27pEsvNV0sS5aUHI+IMPdRUdLf/iZt22ZWOH3tNemOO6TwcFvKBTwCLSMAcAbLl0tr1kjZ2Wba7fvvl7x24q4WV1wh5eaWbgEBUD6EEQA+79gxM8V2xQopPV2aMUM67zzz2tKl0vPPlz4/IED6+OPSM1+YdgtUHGEEgE+yLOmLL8wqpx9+aLpfiqSmloSRCy80u97Wrm26Wrp1M60gRQuTATh3hBEAPqlbNyk5ueR5eLh0991mDZD27UuOX3utuQGoOoQRAD7hyy/NrJZatczzRo1MGGnWTJo0yaz1ceKmcwDch9k0ALza4cNmym3fvmbvlyJ33CG9+66Z8TJiBEEEsBMtIwC8yurVZsZLSorZyfarr0peW7RIGj7cPL7ySnvqA3AqwggAj1VYKP3vf1Lv3iVTalesMKudnmz0aGn6dPfWB6B8CCMAqr2cHOm//5U2bpT27JF++cXcdu82rz/6qBn3IUndu0tjx5pBqFFR5tauHYuOAdUZYQRAtbJvn9lczt9fGjjQHMvPl266yUzHPZnDYQaiWpZ5fMUV5gbAcxBGANgmK8ssHrZ5swkU334r/fqrea1Pn5IwEhoqXX+9VK+e2Q+mceOSW3Q0C44Bno4wAsAtMjLM+I7rry859qc/mQBysjZtpM6dSx+bP79KywNgI8IIgCqTk2NCxLRpZryHVHr/lh49pP37pX79pNatTTjp2lUKCbGrYgB2IIwAqFTr10tTpki//SZ9/bXZ96VIRIRpCYmNNc+nTpVq1mRpdcDXEUYAVMjvv5vdbHfsMGt2tGpljh88aBYTK9K0qRl8Om6cCSMnCg52X70Aqi/CCIByW75ceuUV07qRklJyfPFiadky08LRsaPZ5TYqyjzu1ImWDwBnRhgBcIrCQjPgNDLSBImUFOlvf5M++6z0ec2amXU9Wrc23TE1a0oNG0oJCbaUDcBDEUYAH3f8uLRzp/T999L27dLWrdKSJdKBA2bNj/r1zRTa9u1NGBk5Uho2zMx2qVvX7uoBeAPCCOCjCgul2bOlu++WsrNPfd3PzwxCrV/frONx993ShAmmtQQAKhNhBPByv/wiff65GWi6e7f08MNmsKmfn5lCm50t1aoldehglk1v2dJMrx0woGQKriS1aGHXLwDg7QgjgJd6/30zgyU1tfTxiAjpn/80jy+4QPriC7PRHINMAdiFMAJ4mZ9+MuM61q0rOdazp3T++WbAaZcuJcdjYswNAOxEGAE8VGGh9PPPZl+X7783YzqCg00XTNEKpmPGSPfdZ9b6AIDqijACeJCCAtPiMXWq2WAuJ6fktYsvlnr1MuM8Jk82023Dw+2qFADKjzACeIj335eGDpWOHi19vEMHs7DYiYNNe/Vyb20AcC4II0A1lZdnZsIUzWLp29esCVKrlhQXJ40da5Zhr8H/igF4OP5vDKgmCgulRYtM98uPP0qbNpnZLp9/bl6PiJB++EE67zzJ39/eWgGgMhFGAJulpEjvvSfNnGnWAjnRDz9I+/ebhcckqW1b99cHAFWNMAK42a+/mlkvdeqY5wsWSOPHm8f+/tI990h9+pixIEWLkwGANyOMAFXs999N18tXX0n/+5/pfpk2zUy7lcyCY/37my6Zv/2NabgAfA9hBKgCeXnSf/8rvf66lJRkBp6eaNeuksd9+kgrVri3PgCoTggjQCUoLJTS0qSGDc3zvLzS03A7dTLrgPTuLV10EZvNAcCJCCNABRw4IG3bJq1ebfZ2WbNGqltX2rrVvF67tjR6tBnvcdttZuApe78AQNkII0A5FRRIN9wgrV0r7d176uvHjkkHD5pQIplVUgEAZ8c4faAMublmmu2rr0qHD5tj/v6mu6UoiDRuLF12mZSYaFpITgwiAIDyo2UEPu/YMbPI2I8/mg3nvvhC2rjRjAORpLAw6cYbzeN//MMEkI4dpdBQ+2oGAG9CGIFPycmRPvpIat9e6tzZHFu1Show4NRzg4JMS0hQUMmxkBDpwgvdUysA+ArCCLzakSPSl19KGzaYFo8vv5Sys6WJE0vCSMeOZqn1jh3NrXNn6dJLpZgYBp0CgDsQRuCVjh0zU2nXrz91jY+GDaXo6NLP09PdWx8AoARhBB6roMCsZvr++9LKlaYL5eOPzWtBQWZhsePHzYqmvXtLPXtK8fFmmXVaPACg+iCMwKOsX2+6Wr780qxseuhQyWsxMaXPnTtXatJEatmS8AEA1RlhBNXWwYPS119Ll19ecuzhh6WlS0ue16xpumMGDzbLqp/o4ovdUiYA4BwRRlAtFBRIO3dKyclmsOmKFebesqRffpEaNTLnXXaZFBAgxcZKfftKcXHmOQDAcxFGYLtp06QHHyxZXOxE7dtLv/5aEkbGjTM3AID3YAVWVCnLklJTpYULpWuuMauY9utn1vYoEhFhgkjNmlK3btKoUdKcOaZFZNMmqVcv++oHAFQ9WkZQaY4fL+kysSzp2mvNBnIZGaXPW7XKDEC96CLzfMAA0z3ToYNUg38jAcDn8H/9cJllSb/9Zma2FN1++sm0cHzzjTnH4TB7u2RkmNaQjh2lH36Q/vIX0zLSv3/J54WFSV262PNbAAD2I4zAJaNHS//9r5SWdupr+/eb/Vz8/uj8mzLFrP3RubMUHOzeOgEAnoMwglIOHizd4rFrl/TttyXrdBw4YIKIv7/pVunRw9w6d5batSsJIpJZUh0AgLNxWJZl2V3E2WRlZSksLEyZmZkKZavUc5aTIwUGlozP+Oc/pRdfNAuIHTly6vm7dknNm5vHRcurd+lCawcA4MzK+/eblhEvt3+/9P33pnVj40YzbuOnn0yo6NrVnBMQYGauFGnVqqTFo0eP0vu49Ojh1vIBAD6AMOIlcnPNwNKi7e7//W9p/Hhp796yz9++vSSM3HCD1Lataeno1EmqU8ctJQMAIIkw4nFyc6XNm01rx6ZN5vFPP0kpKdJbb0k332zOi4goCSLNm0vnn2/W8OjSxdwaNy75zIYNzQ0AADsQRqqx/fvNwNF69czzZcukq66S8vPLPj81teTxRReZtTw6dzYzWgAAqK4II9VAZqZp5Si6bdlixnb89ps0ebI0YYI5r3lzE0Tq1DHdKR07mhksHTqY+8jIks8MDpZ697bn9wAA4ArCiJtYlpSXZ7pVAgJMgJBMF0vR47KcOOajVSvp55+lmJiSqbYAAHg6wkgVyMszC4Nt3Vpy27xZysoyr48cKc2aZR63bGnW7IiONqGkqJWjY0fz+MQuFj8/qUkT9/8eAACqEmGkAnJzzU6y27ebLpXt201IuP9+87rDId14Y9ljO+rUkWrVKnnudJr1PWrXdkvpAABUOxXatXf69Olq1qyZgoKCFBsbq3Xr1p3x/Pfee09t27ZVUFCQOnXqpCVLllSoWHcqLDQh4UTXXy+1bm3CRMuW0sCB0t//Lk2fLi1aVHJeQID05z9LQ4dKTz4pLVggffed6XI5cEB66aXSn0sQAQD4MpdbRubPn6+EhATNmDFDsbGxmjp1qgYMGKCtW7cqIiLilPPXrFmjm266SYmJibrqqqs0d+5cDR48WBs3blTHjh0r5Ueci6NHpR9/NGM3tm0zXSrbtplN3tq2NQuFFSlqBSnSrp05p02bUzd6W7DAPfUDAODpXF4OPjY2Vj179tS0adMkSYWFhYqJidFdd92l8ePHn3L+kCFDlJ2drY8//rj42AUXXKCuXbtqxowZ5frOqloOfv9+qVkzKTu77NfDw81eLUWDRZctM60ebdtKUVGl92EBAAClVcly8Hl5edqwYYMmFM01leTn56f4+HitXbu2zPesXbtWCQkJpY4NGDBAH3744Wm/Jzc3V7m5ucXPMzMzJZkfVZkCA6Xbb5dmz5batzddMK1amS6YVq3MOJDDh0vOj4sreVzWHi4AAKBE0d/ts7V7uBRG9u/fr4KCAkWeuKCFpMjISG3ZsqXM96SlpZV5flpZe9D/ITExUY899tgpx2NiYlwp1yVffGFuAACgch0+fFhhYWGnfb1azqaZMGFCqdaUwsJCHTx4UPXq1ZOjEhfYyMrKUkxMjFJTU9kNuApxnd2Ha+0eXGf34Dq7R1VeZ8uydPjwYTU8y54jLoWR+vXry9/fX+np6aWOp6enKyoqqsz3REVFuXS+JDmdTjmdzlLHwsPDXSnVJaGhofyL7gZcZ/fhWrsH19k9uM7uUVXX+UwtIkVcGoIZGBio7t27KykpqfhYYWGhkpKSFHfigIoTxMXFlTpfkj777LPTng8AAHyLy900CQkJGj58uHr06KFevXpp6tSpys7O1siRIyVJw4YNU6NGjZSYmChJuueee9SvXz89//zzuvLKKzVv3jytX79er732WuX+EgAA4JFcDiNDhgzRvn379MgjjygtLU1du3bV0qVLiwep7tmzR34nzHm98MILNXfuXD300EN68MEHdd555+nDDz+sFmuMOJ1OTZo06ZQuIVQurrP7cK3dg+vsHlxn96gO19nldUYAAAAqE8t2AQAAWxFGAACArQgjAADAVoQRAABgK68PI9OnT1ezZs0UFBSk2NhYrVu37oznv/fee2rbtq2CgoLUqVMnLVmyxE2VejZXrvPMmTPVt29f1alTR3Xq1FF8fPxZ/7mghKv/TheZN2+eHA6HBg8eXLUFeglXr/OhQ4c0ZswYRUdHy+l0qnXr1vz/Rzm4ep2nTp2qNm3aqGbNmoqJidG4ceN07NgxN1XrmVatWqVBgwapYcOGcjgcZ9wbrsjKlSvVrVs3OZ1OtWrVSrNnz67aIi0vNm/ePCswMNCaNWuWtWnTJuu2226zwsPDrfT09DLPX716teXv7289++yz1k8//WQ99NBDVkBAgPXDDz+4uXLP4up1vvnmm63p06db3377rbV582ZrxIgRVlhYmPXLL7+4uXLP4+q1LpKSkmI1atTI6tu3r3XNNde4p1gP5up1zs3NtXr06GFdccUV1pdffmmlpKRYK1eutJKTk91cuWdx9Tq/8847ltPptN555x0rJSXFWrZsmRUdHW2NGzfOzZV7liVLllgTJ060Fi1aZEmyPvjggzOev2vXLis4ONhKSEiwfvrpJ+ull16y/P39raVLl1ZZjV4dRnr16mWNGTOm+HlBQYHVsGFDKzExsczzb7jhBuvKK68sdSw2Ntb629/+VqV1ejpXr/PJ8vPzrZCQEGvOnDlVVaLXqMi1zs/Pty688ELr9ddft4YPH04YKQdXr/Mrr7xitWjRwsrLy3NXiV7B1es8ZswY6+KLLy51LCEhwerdu3eV1ulNyhNG7r//fqtDhw6ljg0ZMsQaMGBAldXltd00eXl52rBhg+Lj44uP+fn5KT4+XmvXri3zPWvXri11viQNGDDgtOejYtf5ZDk5OTp+/Ljq1q1bVWV6hYpe68cff1wRERG69dZb3VGmx6vIdf7oo48UFxenMWPGKDIyUh07dtTkyZNVUFDgrrI9TkWu84UXXqgNGzYUd+Xs2rVLS5Ys0RVXXOGWmn2FHX8Lq+WuvZVh//79KigoKF4ZtkhkZKS2bNlS5nvS0tLKPD8tLa3K6vR0FbnOJ3vggQfUsGHDU/7lR2kVudZffvml3njjDSUnJ7uhQu9Qkeu8a9curVixQrfccouWLFmiHTt26M4779Tx48c1adIkd5TtcSpynW+++Wbt379fffr0kWVZys/P1+23364HH3zQHSX7jNP9LczKytLRo0dVs2bNSv9Or20ZgWd4+umnNW/ePH3wwQcKCgqyuxyvcvjwYQ0dOlQzZ85U/fr17S7HqxUWFioiIkKvvfaaunfvriFDhmjixImaMWOG3aV5lZUrV2ry5Ml6+eWXtXHjRi1atEiLFy/WE088YXdpOEde2zJSv359+fv7Kz09vdTx9PR0RUVFlfmeqKgol85Hxa5zkeeee05PP/20li9frs6dO1dlmV7B1Wu9c+dO7d69W4MGDSo+VlhYKEmqUaOGtm7dqpYtW1Zt0R6oIv9OR0dHKyAgQP7+/sXH2rVrp7S0NOXl5SkwMLBKa/ZEFbnODz/8sIYOHapRo0ZJkjp16qTs7GyNHj1aEydOLLUvGirudH8LQ0NDq6RVRPLilpHAwEB1795dSUlJxccKCwuVlJSkuLi4Mt8TFxdX6nxJ+uyzz057Pip2nSXp2Wef1RNPPKGlS5eqR48e7ijV47l6rdu2basffvhBycnJxberr75a/fv3V3JysmJiYtxZvseoyL/TvXv31o4dO4rDniRt27ZN0dHRBJHTqMh1zsnJOSVwFAVAi23WKo0tfwurbGhsNTBv3jzL6XRas2fPtn766Sdr9OjRVnh4uJWWlmZZlmUNHTrUGj9+fPH5q1evtmrUqGE999xz1ubNm61JkyYxtbccXL3OTz/9tBUYGGgtXLjQ2rt3b/Ht8OHDdv0Ej+HqtT4Zs2nKx9XrvGfPHiskJMQaO3astXXrVuvjjz+2IiIirCeffNKun+ARXL3OkyZNskJCQqx3333X2rVrl/Xpp59aLVu2tG644Qa7foJHOHz4sPXtt99a3377rSXJmjJlivXtt99aP//8s2VZljV+/Hhr6NChxecXTe297777rM2bN1vTp09nau+5eumll6wmTZpYgYGBVq9evayvvvqq+LV+/fpZw4cPL3X+ggULrNatW1uBgYFWhw4drMWLF7u5Ys/kynVu2rSpJemU26RJk9xfuAdy9d/pExFGys/V67xmzRorNjbWcjqdVosWLaynnnrKys/Pd3PVnseV63z8+HHr0UcftVq2bGkFBQVZMTEx1p133mn9/vvv7i/cg3z++edl/n9u0bUdPny41a9fv1Pe07VrVyswMNBq0aKF9eabb1ZpjQ7Lom0LAADYx2vHjAAAAM9AGAEAALYijAAAAFsRRgAAgK0IIwAAwFaEEQAAYCvCCAAAsBVhBMAZrVy5Ug6HQ4cOHXLr986ePVvh4eHn9Bm7d++Ww+E4467Fdv0+ACUII4APczgcZ7w9+uijdpcIwAd47a69AM5u7969xY/nz5+vRx55RFu3bi0+Vrt2ba1fv97lz2WnWgCuoGUE8GFRUVHFt7CwMDkcjlLHateuXXzuhg0b1KNHDwUHB+vCCy8sFVoeffRRde3aVa+//rqaN2+uoKAgSdKhQ4c0atQoNWjQQKGhobr44ov13XffFb/vu+++U//+/RUSEqLQ0FB17979lPCzbNkytWvXTrVr19bAgQNLBajCwkI9/vjjaty4sZxOp7p27aqlS5ee8TcvWbJErVu3Vs2aNdW/f3/t3r37XC4hgEpAGAFQLhMnTtTzzz+v9evXq0aNGvrrX/9a6vUdO3bo/fff16JFi4rHaFx//fXKyMjQJ598og0bNqhbt2665JJLdPDgQUnSLbfcosaNG+ubb77Rhg0bNH78eAUEBBR/Zk5Ojp577jm99dZbWrVqlfbs2aN77723+PUXXnhBzz//vJ577jl9//33GjBggK6++mpt3769zN+Qmpqqa6+9VoMGDVJycrJGjRql8ePHV/KVAuCyKt2GD4DHePPNN62wsLBTjhft+Ll8+fLiY4sXL7YkWUePHrUsy2ztHhAQYGVkZBSf88UXX1ihoaHWsWPHSn1ey5YtrVdffdWyLMsKCQmxZs+efdp6JFk7duwoPjZ9+nQrMjKy+HnDhg2tp556qtT7evbsad15552WZVlWSkqKJcn69ttvLcuyrAkTJljt27cvdf4DDzxgSWLnV8BGtIwAKJfOnTsXP46OjpYkZWRkFB9r2rSpGjRoUPz8u+++05EjR1SvXj3Vrl27+JaSkqKdO3dKkhISEjRq1CjFx8fr6aefLj5eJDg4WC1btiz1vUXfmZWVpd9++029e/cu9Z7evXtr8+bNZf6GzZs3KzY2ttSxuLi4cl8DAFWDAawAyuXE7hOHwyHJjNkoUqtWrVLnHzlyRNHR0Vq5cuUpn1U0ZffRRx/VzTffrMWLF+uTTz7RpEmTNG/ePP35z38+5TuLvteyrMr4OQCqEVpGAFSJbt26KS0tTTVq1FCrVq1K3erXr198XuvWrTVu3Dh9+umnuvbaa/Xmm2+W6/NDQ0PVsGFDrV69utTx1atXq3379mW+p127dlq3bl2pY1999ZWLvwxAZSOMAKgS8fHxiouL0+DBg/Xpp59q9+7dWrNmjSZOnKj169fr6NGjGjt2rFauXKmff/5Zq1ev1jfffKN27dqV+zvuu+8+PfPMM5o/f762bt2q8ePHKzk5Wffcc0+Z599+++3avn277rvvPm3dulVz587V7NmzK+kXA6goumkAVAmHw6ElS5Zo4sSJGjlypPbt26eoqChddNFFioyMlL+/vw4cOKBhw4YpPT1d9evX17XXXqvHHnus3N9x9913KzMzU//4xz+UkZGh9u3b66OPPtJ5551X5vlNmjTR+++/r3Hjxumll15Sr169NHny5FNmBgFwL4dFBywAALAR3TQAAMBWhBEAAGArwggAALAVYQQAANiKMAIAAGxFGAEAALYijAAAAFsRRgAAgK0IIwAAwFaEEQAAYCvCCAAAsBVhBAAA2Or/AUA8vms/XrM0AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best Parameters: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Classification Report (GridSearchCV):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     35544\n",
      "           1       0.14      0.91      0.24        57\n",
      "\n",
      "    accuracy                           0.99     35601\n",
      "   macro avg       0.57      0.95      0.62     35601\n",
      "weighted avg       1.00      0.99      0.99     35601\n",
      "\n",
      "AUC-ROC Score (GridSearchCV): 0.9514560159683475\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# --- Logistic Regression with Threshold Adjustment ---\n",
    "log_model = LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced')\n",
    "log_model.fit(X_train, y_train)\n",
    "y_proba = log_model.predict_proba(X_test)[:, 1]\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "threshold = 0.3  # Adjust threshold as needed\n",
    "y_pred_threshold = (y_proba > threshold).astype(int)\n",
    "print(\"Classification Report (Adjusted Threshold):\\n\", classification_report(y_test, y_pred_threshold))\n",
    "print(\"AUC-ROC Score (Adjusted Threshold):\", roc_auc_score(y_test, y_pred_threshold))\n",
    "\n",
    "# --- Plot Precision-Recall Curve ---\n",
    "plt.plot(thresholds, precision[:-1], \"b--\", label=\"Precision\")\n",
    "plt.plot(thresholds, recall[:-1], \"g-\", label=\"Recall\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.legend(loc=\"center left\")\n",
    "plt.ylim([0, 1])\n",
    "plt.show()\n",
    "\n",
    "# --- GridSearchCV (Optional) ---\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2'], 'solver': ['liblinear', 'saga']}\n",
    "grid_search = GridSearchCV(LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000), param_grid, scoring='recall', cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "best_log_model = grid_search.best_estimator_\n",
    "y_pred_grid = best_log_model.predict(X_test)\n",
    "print(\"Classification Report (GridSearchCV):\\n\", classification_report(y_test, y_pred_grid))\n",
    "print(\"AUC-ROC Score (GridSearchCV):\", roc_auc_score(y_test, y_pred_grid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     35544\n",
      "           1       0.04      0.93      0.08        57\n",
      "\n",
      "    accuracy                           0.97     35601\n",
      "   macro avg       0.52      0.95      0.53     35601\n",
      "weighted avg       1.00      0.97      0.98     35601\n",
      "\n",
      "AUC-ROC Score: 0.9474691116718197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train Logistic Regression model\n",
    "log_model = LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced')\n",
    "log_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = log_model.predict(X_test)\n",
    "\n",
    "# Evaluate Model Performance\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"AUC-ROC Score:\", roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     35544\n",
      "           1       0.04      0.93      0.08        57\n",
      "\n",
      "    accuracy                           0.97     35601\n",
      "   macro avg       0.52      0.95      0.53     35601\n",
      "weighted avg       1.00      0.97      0.98     35601\n",
      "\n",
      "AUC-ROC Score: 0.9484538066977031\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get predicted probabilities\n",
    "y_prob = best_log_model.predict_proba(X_test)[:, 1]  # Probability for class 1 (fraud)\n",
    "\n",
    "# Adjust the threshold (e.g., 0.2 instead of 0.5)\n",
    "threshold = 0.2\n",
    "y_pred_adjusted = (y_prob > threshold).astype(int)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_adjusted))\n",
    "print(\"AUC-ROC Score:\", roc_auc_score(y_test, y_pred_adjusted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     35544\n",
      "           1       0.13      0.91      0.23        57\n",
      "\n",
      "    accuracy                           0.99     35601\n",
      "   macro avg       0.57      0.95      0.61     35601\n",
      "weighted avg       1.00      0.99      0.99     35601\n",
      "\n",
      "AUC-ROC Score: 0.9513856806093559\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Apply SMOTE only to the training set\n",
    "smote = SMOTE(sampling_strategy=0.3, random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train Logistic Regression on SMOTE data\n",
    "log_model_smote = LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000)\n",
    "log_model_smote.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predictions\n",
    "y_pred_smote = log_model_smote.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_smote))\n",
    "print(\"AUC-ROC Score:\", roc_auc_score(y_test, y_pred_smote))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     35544\n",
      "           1       0.74      0.88      0.80        57\n",
      "\n",
      "    accuracy                           1.00     35601\n",
      "   macro avg       0.87      0.94      0.90     35601\n",
      "weighted avg       1.00      1.00      1.00     35601\n",
      "\n",
      "AUC-ROC Score: 0.9383432839357002\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_model = XGBClassifier(scale_pos_weight=100, random_state=42, n_estimators=100, max_depth=5)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_xgb))\n",
    "print(\"AUC-ROC Score:\", roc_auc_score(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     35544\n",
      "           1       0.80      0.86      0.83        57\n",
      "\n",
      "    accuracy                           1.00     35601\n",
      "   macro avg       0.90      0.93      0.92     35601\n",
      "weighted avg       1.00      1.00      1.00     35601\n",
      "\n",
      "AUC-ROC Score: 0.9514560159683475\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Initialize XGBoost with imbalance handling\n",
    "xgb_model = XGBClassifier(\n",
    "    scale_pos_weight=10,  # Helps in handling class imbalance\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=200,\n",
    "    eval_metric=\"logloss\",\n",
    "    use_label_encoder=False,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "print(\"AUC-ROC Score:\", roc_auc_score(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC Score: 0.9296557565419288\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC-ROC Score:\", roc_auc_score(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:57:34] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:57:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:57:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:57:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:57:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:57:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:57:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:57:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:57:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:57:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:57:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:57:45] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:57:49] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:57:50] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:57:50] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:57:55] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:57:56] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:57:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:57:59] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:57:59] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:00] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:01] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:01] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:02] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:02] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:02] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:04] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:06] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:06] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:07] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:18] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'scale_pos_weight': 10, 'n_estimators': 100, 'max_depth': 4, 'learning_rate': 0.05}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     35544\n",
      "           1       0.81      0.84      0.83        57\n",
      "\n",
      "    accuracy                           1.00     35601\n",
      "   macro avg       0.91      0.92      0.91     35601\n",
      "weighted avg       1.00      1.00      1.00     35601\n",
      "\n",
      "AUC-ROC Score: 0.9208978937891656\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'scale_pos_weight': [5, 10, 15]\n",
    "}\n",
    "\n",
    "# Initialize XGBoost model\n",
    "xgb_model = XGBClassifier(\n",
    "    eval_metric=\"logloss\",\n",
    "    use_label_encoder=False,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Use Stratified K-Fold\n",
    "cv_strategy = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Randomized Search\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10,  # Try 10 random combinations\n",
    "    scoring='roc_auc',\n",
    "    cv=cv_strategy,\n",
    "    verbose=0,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best Parameters\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "\n",
    "# Predict with the best model\n",
    "best_xgb = random_search.best_estimator_\n",
    "y_pred_best = best_xgb.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "print(\"AUC-ROC Score:\", roc_auc_score(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:40] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:40] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:40] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:43] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:43] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:48] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:48] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:48] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:51] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:52] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:58:53] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:00] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:00] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:01] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:01] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:02] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:02] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:07] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:07] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:08] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:08] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:08] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:09] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:09] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:09] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:11] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:13] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:14] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:18] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:18] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:19] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:23] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:23] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:23] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:27] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:27] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:27] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:27] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:31] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:33] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:34] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:38] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:39] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:39] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:41] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:43] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:46] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:46] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:46] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:47] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:47] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:50] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:50] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:51] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:53] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:55] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:59:55] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:00] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:02] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:09] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:09] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:09] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:10] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:11] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:15] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:17] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:18] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:20] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:20] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:22] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:22] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:24] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:24] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:24] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:27] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:27] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:27] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:29] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:29] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:31] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:34] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:38] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:45] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:46] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:47] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:48] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:48] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:50] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:50] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:51] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:52] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:52] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:54] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:57] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:00:59] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:01] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:01] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:02] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:03] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:04] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:09] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:10] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:11] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:11] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:13] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:15] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:16] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:18] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:23] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:24] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:24] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:27] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:28] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:29] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:33] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:34] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:40] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:42] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:46] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:48] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:48] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:49] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:51] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:57] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:01:59] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:01] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:01] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:02] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:07] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:08] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:09] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:10] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:13] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:18] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:18] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:19] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:20] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:21] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:22] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:23] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:24] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:25] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:27] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:29] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:31] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:31] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:32] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:32] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:33] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:33] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:38] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:42] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:42] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:43] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:45] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:46] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:46] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:47] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:48] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:51] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:54] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:56] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:02:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:00] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:01] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:02] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:03] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:03] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:04] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:04] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:04] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:04] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:06] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:10] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:16] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:16] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:18] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:19] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:25] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:26] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:28] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:29] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:29] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:30] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:39] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:42] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:43] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:43] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:47] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:47] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:51] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:52] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:03:53] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:04:00] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:04:00] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:04:01] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:04:02] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:04:08] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:04:08] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:04:21] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300, 'scale_pos_weight': 10}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     35544\n",
      "           1       0.96      0.82      0.89        57\n",
      "\n",
      "    accuracy                           1.00     35601\n",
      "   macro avg       0.98      0.91      0.94     35601\n",
      "weighted avg       1.00      1.00      1.00     35601\n",
      "\n",
      "AUC-ROC Score: 0.9122525676107893\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [4, 6, 8],          # Try different tree depths\n",
    "    'learning_rate': [0.01, 0.05, 0.1],  # Try smaller learning rates\n",
    "    'n_estimators': [100, 200, 300],   # Number of boosting rounds\n",
    "    'scale_pos_weight': [5, 10, 15]  # Adjust for class imbalance\n",
    "}\n",
    "\n",
    "# Initialize XGBoost\n",
    "xgb_model = XGBClassifier(\n",
    "    eval_metric=\"logloss\",\n",
    "    use_label_encoder=False,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',  # Optimize for AUC-ROC score\n",
    "    cv=3,  # 3-Fold Cross Validation\n",
    "    verbose=0,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train on training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best Parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Predict with the best model\n",
    "best_xgb = grid_search.best_estimator_\n",
    "y_pred_best = best_xgb.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "print(\"AUC-ROC Score:\", roc_auc_score(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:08:33] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:08:33] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:08:33] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:08:34] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:08:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:08:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:08:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:08:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:08:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:08:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:08:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:08:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:08:39] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:08:41] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:08:42] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:08:46] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:08:47] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:08:47] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:08:48] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:08:50] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:08:50] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:08:51] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:08:51] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:08:51] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:08:53] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:08:55] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:08:57] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:08:59] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:09:08] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:09:11] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:09:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:09:13] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:09:13] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:09:14] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:09:15] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:09:19] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:09:22] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:09:23] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:09:24] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:09:25] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:09:26] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:09:26] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:09:27] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:09:29] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:09:31] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:09:31] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:09:32] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:09:34] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:09:43] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:09:46] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:09:52] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:09:54] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:09:54] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:09:54] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:09:55] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:09:55] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:09:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:09:59] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:10:03] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:10:09] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:10:14] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:10:14] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:10:16] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:10:17] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:10:19] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:10:20] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:10:24] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:10:24] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:10:26] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:10:27] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:10:28] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:10:31] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:10:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:10:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:10:38] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:10:45] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:10:50] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:10:51] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:10:57] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:11:01] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:11:02] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:11:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:11:06] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:11:09] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:11:16] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:11:18] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:11:19] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:11:24] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:11:24] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:11:27] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:11:32] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:11:32] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:11:32] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:11:33] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:11:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:11:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:11:40] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:11:40] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:11:42] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:11:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:11:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:11:48] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:11:48] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:11:53] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:11:53] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:11:53] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:11:56] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:11:56] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:11:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:11:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:12:01] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:12:02] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:12:06] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:12:08] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:12:10] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:12:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:12:13] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:12:14] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:12:14] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:12:15] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:12:17] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:12:17] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:12:19] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:12:21] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:12:21] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:12:21] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:12:22] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:12:24] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:12:27] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:12:34] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:12:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:12:38] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:12:38] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:12:39] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:12:41] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:12:43] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:12:48] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:12:50] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:12:56] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:12:56] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:13:04] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:13:04] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:13:06] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:13:07] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:13:07] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:13:11] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:13:11] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:13:15] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:13:15] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:13:19] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:13:24] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:13:45] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:13:46] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:13:47] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:13:47] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:13:47] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:14:00] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:14:03] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:14:03] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:14:06] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:14:08] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:14:13] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:14:15] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:14:23] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:14:26] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:14:32] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:14:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:14:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:14:38] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:14:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:14:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:14:47] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:14:50] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:14:50] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:14:50] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:14:52] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:14:53] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:14:54] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:14:55] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:14:57] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:14:57] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:15:01] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:15:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:15:07] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:15:10] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:15:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:15:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:15:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:15:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:15:13] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:15:14] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:15:15] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:15:22] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:15:25] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:15:28] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:15:28] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:15:28] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:15:30] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:15:33] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:15:33] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:15:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:15:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:15:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:15:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:15:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:15:38] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:15:45] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:15:45] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:15:46] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:15:49] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:15:49] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:15:50] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:15:51] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:16:00] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:16:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:16:07] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:16:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:16:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:16:13] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:16:16] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:16:16] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:16:23] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:16:24] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:16:24] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:16:29] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:16:30] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:16:32] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:16:34] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:16:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:16:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:16:40] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:16:41] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:16:41] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:16:42] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:16:45] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:16:46] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:16:49] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:16:51] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:16:52] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:16:54] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:17:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:17:08] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:17:09] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:17:30] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300, 'scale_pos_weight': 15}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'classification_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m y_pred_best \u001b[38;5;241m=\u001b[39m best_xgb\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m(y_test, y_pred_best))\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUC-ROC Score:\u001b[39m\u001b[38;5;124m\"\u001b[39m, roc_auc_score(y_test, y_pred_best))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classification_report' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [4, 6, 8],          # Try different tree depths\n",
    "    'learning_rate': [0.01, 0.05, 0.1],  # Try smaller learning rates\n",
    "    'n_estimators': [100, 200, 300],   # Number of boosting rounds\n",
    "    'scale_pos_weight': [5, 10, 15]  # Adjust for class imbalance\n",
    "}\n",
    "\n",
    "# Initialize XGBoost\n",
    "xgb_model = XGBClassifier(\n",
    "    eval_metric=\"aucpr\",  # Try 'aucpr' instead of 'logloss'\n",
    "    scale_pos_weight=10,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=200,\n",
    "    use_label_encoder=False,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',  # Optimize for AUC-ROC score\n",
    "    cv=3,  # 3-Fold Cross Validation\n",
    "    verbose=0,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train on training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best Parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Predict with the best model\n",
    "best_xgb = grid_search.best_estimator_\n",
    "y_pred_best = best_xgb.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "print(\"AUC-ROC Score:\", roc_auc_score(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     35544\n",
      "           1       0.79      0.86      0.82        57\n",
      "\n",
      "    accuracy                           1.00     35601\n",
      "   macro avg       0.90      0.93      0.91     35601\n",
      "weighted avg       1.00      1.00      1.00     35601\n",
      "\n",
      "AUC-ROC Score: 0.9296416894701305\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_best))\n",
    "print(\"AUC-ROC Score:\", roc_auc_score(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn version: 1.6.1\n",
      "XGBoost version: 1.6.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import xgboost\n",
    "print(\"scikit-learn version:\", sklearn.__version__)\n",
    "print(\"XGBoost version:\", xgboost.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 42645, number of negative: 213226\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018092 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8160\n",
      "[LightGBM] [Info] Number of data points in the train set: 255871, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166666 -> initscore=-1.609443\n",
      "[LightGBM] [Info] Start training from score -1.609443\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     35544\n",
      "           1       0.69      0.88      0.78        57\n",
      "\n",
      "    accuracy                           1.00     35601\n",
      "   macro avg       0.85      0.94      0.89     35601\n",
      "weighted avg       1.00      1.00      1.00     35601\n",
      "\n",
      "AUC-ROC Score: 0.9382870156485068\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Initialize LightGBM\n",
    "lgbm_model = LGBMClassifier(\n",
    "    boosting_type='gbdt',\n",
    "    num_leaves=31,\n",
    "    max_depth=-1,\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=200,\n",
    "    scale_pos_weight=10,  # Handles class imbalance\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "lgbm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lgbm = lgbm_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(classification_report(y_test, y_pred_lgbm))\n",
    "print(\"AUC-ROC Score:\", roc_auc_score(y_test, y_pred_lgbm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6664/6664 [==============================] - 17s 2ms/step - loss: 0.8346\n",
      "Epoch 2/10\n",
      "6664/6664 [==============================] - 19s 3ms/step - loss: 0.7957\n",
      "Epoch 3/10\n",
      "6664/6664 [==============================] - 21s 3ms/step - loss: 0.7800\n",
      "Epoch 4/10\n",
      "6664/6664 [==============================] - 20s 3ms/step - loss: 0.7757\n",
      "Epoch 5/10\n",
      "6664/6664 [==============================] - 21s 3ms/step - loss: 0.7736\n",
      "Epoch 6/10\n",
      "6664/6664 [==============================] - 17s 3ms/step - loss: 0.7701\n",
      "Epoch 7/10\n",
      "6664/6664 [==============================] - 19s 3ms/step - loss: 0.7663\n",
      "Epoch 8/10\n",
      "6664/6664 [==============================] - 16s 2ms/step - loss: 0.7646\n",
      "Epoch 9/10\n",
      "6664/6664 [==============================] - 20s 3ms/step - loss: 0.7634\n",
      "Epoch 10/10\n",
      "6664/6664 [==============================] - 18s 3ms/step - loss: 0.7626\n",
      "1113/1113 [==============================] - 1s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     35544\n",
      "           1       0.03      0.84      0.05        57\n",
      "\n",
      "    accuracy                           0.95     35601\n",
      "   macro avg       0.51      0.90      0.51     35601\n",
      "weighted avg       1.00      0.95      0.97     35601\n",
      "\n",
      "AUC-ROC Score: 0.8966884632242321\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Define the autoencoder architecture\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "autoencoder = models.Sequential([\n",
    "    layers.Dense(24, activation='relu', input_shape=(input_dim,)),\n",
    "    layers.Dense(12, activation='relu'),\n",
    "    layers.Dense(6, activation='relu'),\n",
    "    layers.Dense(12, activation='relu'),\n",
    "    layers.Dense(24, activation='relu'),\n",
    "    layers.Dense(input_dim, activation='sigmoid')  # Output should match input\n",
    "])\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mse', )\n",
    "\n",
    "# Train the autoencoder on non-fraud data\n",
    "autoencoder.fit(X_train[y_train == 0], X_train[y_train == 0], epochs=10, batch_size=32)\n",
    "\n",
    "# Reconstruction loss can help detect fraud\n",
    "reconstruction = autoencoder.predict(X_test)\n",
    "reconstruction_loss = tf.keras.losses.mean_squared_error(X_test, reconstruction)\n",
    "threshold = np.percentile(reconstruction_loss, 95)\n",
    "\n",
    "fraud_predictions = tf.cast(reconstruction_loss > threshold, tf.int32) # Use tf.cast\n",
    "#or\n",
    "#fraud_predictions = tf.cast(tf.greater(reconstruction_loss, threshold), tf.int32)\n",
    "\n",
    "print(classification_report(y_test, fraud_predictions.numpy())) #convert to numpy array for the report.\n",
    "print(\"AUC-ROC Score:\", roc_auc_score(y_test, fraud_predictions.numpy())) #convert to numpy array for the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_94537/1301334812.py:18: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  autoencoder_model = KerasClassifier(build_fn=create_autoencoder, input_dim=input_dim, epochs=10, batch_size=32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8873/8885 [============================>.] - ETA: 0s - loss: 0.7290\n",
      "Epoch 1: loss improved from inf to 0.72902, saving model to best_autoencoder.h5\n",
      "Epoch 1: Best loss so far 0.7290\n",
      "8885/8885 [==============================] - 27s 3ms/step - loss: 0.7290\n",
      "Epoch 2/10\n",
      "8870/8885 [============================>.] - ETA: 0s - loss: 0.6950\n",
      "Epoch 2: loss improved from 0.72902 to 0.69552, saving model to best_autoencoder.h5\n",
      "Epoch 2: Best loss so far 0.6955\n",
      "8885/8885 [==============================] - 29s 3ms/step - loss: 0.6955\n",
      "Epoch 3/10\n",
      "8885/8885 [==============================] - ETA: 0s - loss: 0.6882\n",
      "Epoch 3: loss improved from 0.69552 to 0.68815, saving model to best_autoencoder.h5\n",
      "Epoch 3: Best loss so far 0.6882\n",
      "8885/8885 [==============================] - 28s 3ms/step - loss: 0.6882\n",
      "Epoch 4/10\n",
      "8869/8885 [============================>.] - ETA: 0s - loss: 0.6831\n",
      "Epoch 4: loss improved from 0.68815 to 0.68317, saving model to best_autoencoder.h5\n",
      "Epoch 4: Best loss so far 0.6832\n",
      "8885/8885 [==============================] - 27s 3ms/step - loss: 0.6832\n",
      "Epoch 5/10\n",
      "8883/8885 [============================>.] - ETA: 0s - loss: 0.6801\n",
      "Epoch 5: loss improved from 0.68317 to 0.68017, saving model to best_autoencoder.h5\n",
      "Epoch 5: Best loss so far 0.6802\n",
      "8885/8885 [==============================] - 28s 3ms/step - loss: 0.6802\n",
      "Epoch 6/10\n",
      "8884/8885 [============================>.] - ETA: 0s - loss: 0.6780\n",
      "Epoch 6: loss improved from 0.68017 to 0.67798, saving model to best_autoencoder.h5\n",
      "Epoch 6: Best loss so far 0.6780\n",
      "8885/8885 [==============================] - 25s 3ms/step - loss: 0.6780\n",
      "Epoch 7/10\n",
      "8871/8885 [============================>.] - ETA: 0s - loss: 0.6768\n",
      "Epoch 7: loss improved from 0.67798 to 0.67675, saving model to best_autoencoder.h5\n",
      "Epoch 7: Best loss so far 0.6767\n",
      "8885/8885 [==============================] - 31s 3ms/step - loss: 0.6767\n",
      "Epoch 8/10\n",
      "8867/8885 [============================>.] - ETA: 0s - loss: 0.6765\n",
      "Epoch 8: loss improved from 0.67675 to 0.67616, saving model to best_autoencoder.h5\n",
      "Epoch 8: Best loss so far 0.6762\n",
      "8885/8885 [==============================] - 29s 3ms/step - loss: 0.6762\n",
      "Epoch 9/10\n",
      "8885/8885 [==============================] - ETA: 0s - loss: 0.6759\n",
      "Epoch 9: loss improved from 0.67616 to 0.67586, saving model to best_autoencoder.h5\n",
      "Epoch 9: Best loss so far 0.6759\n",
      "8885/8885 [==============================] - 28s 3ms/step - loss: 0.6759\n",
      "Epoch 10/10\n",
      "8876/8885 [============================>.] - ETA: 0s - loss: 0.6739\n",
      "Epoch 10: loss improved from 0.67586 to 0.67387, saving model to best_autoencoder.h5\n",
      "Epoch 10: Best loss so far 0.6739\n",
      "8885/8885 [==============================] - 29s 3ms/step - loss: 0.6739\n",
      "4443/4443 [==============================] - 7s 1ms/step - loss: 0.4471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 472, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/keras/wrappers/scikit_learn.py\", line 335, in score\n",
      "    raise ValueError(\n",
      "ValueError: The model is not configured to compute accuracy. You should pass `metrics=[\"accuracy\"]` to the `model.compile()` method.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8881/8885 [============================>.] - ETA: 0s - loss: 0.7378\n",
      "Epoch 1: loss did not improve from 0.67387\n",
      "8885/8885 [==============================] - 30s 3ms/step - loss: 0.7377\n",
      "Epoch 2/10\n",
      "8878/8885 [============================>.] - ETA: 0s - loss: 0.7002\n",
      "Epoch 2: loss did not improve from 0.67387\n",
      "8885/8885 [==============================] - 30s 3ms/step - loss: 0.7001\n",
      "Epoch 3/10\n",
      "8869/8885 [============================>.] - ETA: 0s - loss: 0.6946\n",
      "Epoch 3: loss did not improve from 0.67387\n",
      "8885/8885 [==============================] - 30s 3ms/step - loss: 0.6942\n",
      "Epoch 4/10\n",
      "8878/8885 [============================>.] - ETA: 0s - loss: 0.6908\n",
      "Epoch 4: loss did not improve from 0.67387\n",
      "8885/8885 [==============================] - 28s 3ms/step - loss: 0.6908\n",
      "Epoch 5/10\n",
      "8885/8885 [==============================] - ETA: 0s - loss: 0.6886\n",
      "Epoch 5: loss did not improve from 0.67387\n",
      "8885/8885 [==============================] - 25s 3ms/step - loss: 0.6886\n",
      "Epoch 6/10\n",
      "8885/8885 [==============================] - ETA: 0s - loss: 0.6880\n",
      "Epoch 6: loss did not improve from 0.67387\n",
      "8885/8885 [==============================] - 26s 3ms/step - loss: 0.6880\n",
      "Epoch 7/10\n",
      "8883/8885 [============================>.] - ETA: 0s - loss: 0.6873\n",
      "Epoch 7: loss did not improve from 0.67387\n",
      "8885/8885 [==============================] - 25s 3ms/step - loss: 0.6872\n",
      "Epoch 8/10\n",
      "8867/8885 [============================>.] - ETA: 0s - loss: 0.6870\n",
      "Epoch 8: loss did not improve from 0.67387\n",
      "8885/8885 [==============================] - 23s 3ms/step - loss: 0.6872\n",
      "Epoch 9/10\n",
      "8873/8885 [============================>.] - ETA: 0s - loss: 0.6874\n",
      "Epoch 9: loss did not improve from 0.67387\n",
      "8885/8885 [==============================] - 26s 3ms/step - loss: 0.6876\n",
      "Epoch 10/10\n",
      "8877/8885 [============================>.] - ETA: 0s - loss: 0.6863\n",
      "Epoch 10: loss did not improve from 0.67387\n",
      "8885/8885 [==============================] - 27s 3ms/step - loss: 0.6862\n",
      "4443/4443 [==============================] - 6s 1ms/step - loss: 0.4746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 472, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/keras/wrappers/scikit_learn.py\", line 335, in score\n",
      "    raise ValueError(\n",
      "ValueError: The model is not configured to compute accuracy. You should pass `metrics=[\"accuracy\"]` to the `model.compile()` method.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8874/8885 [============================>.] - ETA: 0s - loss: 0.7306\n",
      "Epoch 1: loss did not improve from 0.67387\n",
      "8885/8885 [==============================] - 25s 3ms/step - loss: 0.7306\n",
      "Epoch 2/10\n",
      "8875/8885 [============================>.] - ETA: 0s - loss: 0.6923\n",
      "Epoch 2: loss did not improve from 0.67387\n",
      "8885/8885 [==============================] - 39s 4ms/step - loss: 0.6924\n",
      "Epoch 3/10\n",
      "8871/8885 [============================>.] - ETA: 0s - loss: 0.6828\n",
      "Epoch 3: loss did not improve from 0.67387\n",
      "8885/8885 [==============================] - 27s 3ms/step - loss: 0.6830\n",
      "Epoch 4/10\n",
      "8875/8885 [============================>.] - ETA: 0s - loss: 0.6805\n",
      "Epoch 4: loss did not improve from 0.67387\n",
      "8885/8885 [==============================] - 26s 3ms/step - loss: 0.6803\n",
      "Epoch 5/10\n",
      "8447/8885 [===========================>..] - ETA: 1s - loss: 0.6776"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 65\u001b[0m\n\u001b[1;32m     62\u001b[0m best_result_callback \u001b[38;5;241m=\u001b[39m BestResultCallback()\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Perform Grid Search with both callbacks\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_result_callback\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Best Parameters\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1020\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1570\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1571\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    967\u001b[0m         )\n\u001b[1;32m    968\u001b[0m     )\n\u001b[0;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    993\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/utils/parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:866\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    864\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    865\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 866\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/keras/wrappers/scikit_learn.py:248\u001b[0m, in \u001b[0;36mKerasClassifier.fit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid shape for y: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape))\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_)\n\u001b[0;32m--> 248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/keras/wrappers/scikit_learn.py:175\u001b[0m, in \u001b[0;36mBaseWrapper.fit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m fit_args \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_sk_params(Sequential\u001b[38;5;241m.\u001b[39mfit))\n\u001b[1;32m    173\u001b[0m fit_args\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[0;32m--> 175\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the autoencoder model creation function\n",
    "def create_autoencoder(input_dim):\n",
    "    autoencoder = models.Sequential([\n",
    "        layers.Dense(128, activation='relu', input_shape=(input_dim,)),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(input_dim, activation='sigmoid')\n",
    "    ])\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    return autoencoder\n",
    "\n",
    "# Define the input dimension (replace X_train.shape[1] with the actual value)\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "# Wrap the Keras model as a classifier\n",
    "autoencoder_model = KerasClassifier(build_fn=create_autoencoder, input_dim=input_dim, epochs=10, batch_size=32)\n",
    "\n",
    "# Define the hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'epochs': [10, 20, 30],  # Number of training epochs\n",
    "    'batch_size': [16, 32],  # Batch size\n",
    "    'input_dim': [input_dim]  # Input dimension (you can experiment with other parameters)\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=autoencoder_model, param_grid=param_grid, cv=3, verbose=0)\n",
    "\n",
    "# Define the custom callback to track the best result\n",
    "class BestResultCallback(Callback):\n",
    "    def __init__(self):\n",
    "        super(BestResultCallback, self).__init__()\n",
    "        self.best_loss = float('inf')  # Initialize with a very high value\n",
    "        self.best_epoch = 0\n",
    "        self.losses = []  # List to store the loss for each epoch\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Save the loss for the current epoch\n",
    "        self.losses.append(logs['loss'])\n",
    "\n",
    "        # If the current loss is better than the previous best, update\n",
    "        if logs['loss'] < self.best_loss:\n",
    "            self.best_loss = logs['loss']\n",
    "            self.best_epoch = epoch\n",
    "            print(f\"Epoch {epoch + 1}: Best loss so far {self.best_loss:.4f}\")\n",
    "\n",
    "    def get_best_results(self):\n",
    "        return self.best_loss, self.best_epoch, self.losses\n",
    "\n",
    "\n",
    "# Create the ModelCheckpoint callback to save the best model weights\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_autoencoder.h5',  # Path to save the model\n",
    "    monitor='loss',         # Monitor the training loss\n",
    "    verbose=1,              # Print when saving the best weights\n",
    "    save_best_only=True,    # Save only the best model\n",
    "    restore_best_weights=True  # Restore the best weights after training\n",
    ")\n",
    "\n",
    "# Create the custom callback to track the best result\n",
    "best_result_callback = BestResultCallback()\n",
    "\n",
    "# Perform Grid Search with both callbacks\n",
    "grid_search.fit(\n",
    "    X_train[y_train == 0], X_train[y_train == 0],\n",
    "    callbacks=[checkpoint, best_result_callback]\n",
    ")\n",
    "\n",
    "# Best Parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Get the best results tracked by the custom callback\n",
    "best_loss, best_epoch, losses = best_result_callback.get_best_results()\n",
    "print(f\"Best loss achieved: {best_loss:.4f} at epoch {best_epoch + 1}\")\n",
    "\n",
    "# Predict with the best model\n",
    "best_autoencoder = grid_search.best_estimator_\n",
    "reconstruction = best_autoencoder.predict(X_test)\n",
    "reconstruction_loss = tf.keras.losses.mean_squared_error(X_test, reconstruction)\n",
    "threshold = np.percentile(reconstruction_loss, 95)\n",
    "\n",
    "fraud_predictions = tf.cast(reconstruction_loss > threshold, tf.int32)\n",
    "\n",
    "# Evaluate\n",
    "print(classification_report(y_test, fraud_predictions.numpy()))\n",
    "print(\"AUC-ROC Score:\", roc_auc_score(y_test, fraud_predictions.numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_88225/4204032684.py:25: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  autoencoder_model = KerasClassifier(build_fn=create_autoencoder, input_dim=input_dim, epochs=10, batch_size=32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 14:27:44.174200: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8885/8885 [==============================] - 29s 3ms/step - loss: 0.7348\n",
      "Epoch 2/10\n",
      "8885/8885 [==============================] - 27s 3ms/step - loss: 0.7117\n",
      "Epoch 3/10\n",
      "8885/8885 [==============================] - 27s 3ms/step - loss: 0.7050\n",
      "Epoch 4/10\n",
      "8885/8885 [==============================] - 29s 3ms/step - loss: 0.7011\n",
      "Epoch 5/10\n",
      "8885/8885 [==============================] - 29s 3ms/step - loss: 0.6979\n",
      "Epoch 6/10\n",
      "8885/8885 [==============================] - 28s 3ms/step - loss: 0.6949\n",
      "Epoch 7/10\n",
      "8885/8885 [==============================] - 26s 3ms/step - loss: 0.6936\n",
      "Epoch 8/10\n",
      "8885/8885 [==============================] - 26s 3ms/step - loss: 0.6922\n",
      "Epoch 9/10\n",
      "8885/8885 [==============================] - 23s 3ms/step - loss: 0.6899\n",
      "Epoch 10/10\n",
      "8885/8885 [==============================] - 28s 3ms/step - loss: 0.6892\n",
      "4443/4443 [==============================] - 6s 1ms/step - loss: 0.4729\n",
      "[CV] END .............batch_size=16, epochs=10, input_dim=32; total time= 4.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 472, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"/home/mahdi/.pyenv/versions/lewagon/lib/python3.10/site-packages/keras/wrappers/scikit_learn.py\", line 335, in score\n",
      "    raise ValueError(\n",
      "ValueError: The model is not configured to compute accuracy. You should pass `metrics=[\"accuracy\"]` to the `model.compile()` method.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8885/8885 [==============================] - 28s 3ms/step - loss: 0.7378\n",
      "Epoch 2/10\n",
      "8885/8885 [==============================] - 31s 3ms/step - loss: 0.7001\n",
      "Epoch 3/10\n",
      "8885/8885 [==============================] - 29s 3ms/step - loss: 0.6940\n",
      "Epoch 4/10\n",
      "8885/8885 [==============================] - 28s 3ms/step - loss: 0.6910\n",
      "Epoch 5/10\n",
      "2839/8885 [========>.....................] - ETA: 16s - loss: 0.6856"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mautoencoder_model, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Perform Grid Search\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Best Parameters\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1020\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1570\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1571\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    967\u001b[0m         )\n\u001b[1;32m    968\u001b[0m     )\n\u001b[0;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    993\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/utils/parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:866\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    864\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    865\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 866\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/keras/wrappers/scikit_learn.py:248\u001b[0m, in \u001b[0;36mKerasClassifier.fit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid shape for y: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape))\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_)\n\u001b[0;32m--> 248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/keras/wrappers/scikit_learn.py:175\u001b[0m, in \u001b[0;36mBaseWrapper.fit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m fit_args \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_sk_params(Sequential\u001b[38;5;241m.\u001b[39mfit))\n\u001b[1;32m    173\u001b[0m fit_args\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[0;32m--> 175\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/keras/engine/training.py:1555\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m   1552\u001b[0m     data_handler\u001b[38;5;241m.\u001b[39m_initial_step \u001b[38;5;241m=\u001b[39m data_handler\u001b[38;5;241m.\u001b[39m_initial_step \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1553\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_load_initial_step_from_ckpt()\n\u001b[1;32m   1554\u001b[0m     )\n\u001b[0;32m-> 1555\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[1;32m   1556\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m             epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m             _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m         ):\n\u001b[1;32m   1563\u001b[0m             callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/keras/engine/data_adapter.py:1374\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[1;32m   1373\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1374\u001b[0m original_spe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m   1375\u001b[0m can_run_full_execution \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1376\u001b[0m     original_spe \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1377\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m original_spe\n\u001b[1;32m   1379\u001b[0m )\n\u001b[1;32m   1381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/python/ops/resource_variable_ops.py:637\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    636\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    638\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    639\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/python/ops/resource_variable_ops.py:728\u001b[0m, in \u001b[0;36mBaseResourceVariable.read_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    725\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_variable_op()\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# Return an identity so it can get placed on whatever device the context\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# specifies instead of the device where the variable is.\u001b[39;00m\n\u001b[0;32m--> 728\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43midentity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py:294\u001b[0m, in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgraph\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    291\u001b[0m   \u001b[38;5;66;03m# Make sure we get an input with handle data attached from resource\u001b[39;00m\n\u001b[1;32m    292\u001b[0m   \u001b[38;5;66;03m# variables. Variables have correct handle data when graph building.\u001b[39;00m\n\u001b[1;32m    293\u001b[0m   \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m--> 294\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_array_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43midentity\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# Propagate handle data for happier shape inference for resource variables.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_handle_data\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/python/ops/gen_array_ops.py:4069\u001b[0m, in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m   4067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   4068\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 4069\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4070\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIdentity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4071\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   4072\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# Define a function to create the autoencoder model\n",
    "def create_autoencoder(input_dim):\n",
    "    autoencoder = models.Sequential([\n",
    "        layers.Dense(128, activation='relu', input_shape=(input_dim,)),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(input_dim, activation='sigmoid')\n",
    "    ])\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    return autoencoder\n",
    "\n",
    "# Define the input dimension (replace X_train.shape[1] with the actual value)\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "# Wrap the Keras model as a classifier\n",
    "autoencoder_model = KerasClassifier(build_fn=create_autoencoder, input_dim=input_dim, epochs=10, batch_size=32)\n",
    "\n",
    "# Define the hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'epochs': [10, 20, 30],  # Number of training epochs\n",
    "    'batch_size': [16, 32],  # Batch size\n",
    "    'input_dim': [input_dim]  # Input dimension (you can experiment with other parameters)\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=autoencoder_model, param_grid=param_grid, cv=3, verbose=0)\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search.fit(X_train[y_train == 0], X_train[y_train == 0])\n",
    "\n",
    "# Best Parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Predict with the best model\n",
    "best_autoencoder = grid_search.best_estimator_\n",
    "reconstruction = best_autoencoder.predict(X_test)\n",
    "reconstruction_loss = tf.keras.losses.mean_squared_error(X_test, reconstruction)\n",
    "threshold = np.percentile(reconstruction_loss, 95)\n",
    "\n",
    "fraud_predictions = tf.cast(reconstruction_loss > threshold, tf.int32)\n",
    "\n",
    "# Evaluate\n",
    "print(classification_report(y_test, fraud_predictions.numpy()))\n",
    "print(\"AUC-ROC Score:\", roc_auc_score(y_test, fraud_predictions.numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Initialize SHAP Explainer\n",
    "explainer = shap.Explainer(best_model)\n",
    "shap_values = explainer(X_test_scaled)\n",
    "\n",
    "# Visualize feature importance\n",
    "shap.summary_plot(shap_values, X_test)\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Save model\n",
    "joblib.dump(best_model, \"fraud_detection_model.pkl\")\n",
    "\n",
    "# Load model for future use\n",
    "model_loaded = joblib.load(\"fraud_detection_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(best_model, \"fraud_detection_model.pkl\")\n",
    "\n",
    "# Save the preprocessing pipeline as well\n",
    "joblib.dump(preprocessor, \"preprocessing_pipeline.pkl\")\n",
    "\n",
    "print(\"Model and preprocessing pipeline saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install fastapi uvicorn joblib pandas numpy\n",
    "uvicorn main:app --host 0.0.0.0 --port 8000 --reload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Load the trained model and preprocessing pipeline\n",
    "model = joblib.load(\"fraud_detection_model.pkl\")\n",
    "preprocessor = joblib.load(\"preprocessing_pipeline.pkl\")\n",
    "\n",
    "# Initialize FastAPI app\n",
    "app = FastAPI()\n",
    "\n",
    "# Define the request format\n",
    "class Transaction(BaseModel):\n",
    "    V1: float\n",
    "    V2: float\n",
    "    V3: float\n",
    "    V4: float\n",
    "    V5: float\n",
    "    V6: float\n",
    "    V7: float\n",
    "    V8: float\n",
    "    V9: float\n",
    "    V10: float\n",
    "    V11: float\n",
    "    V12: float\n",
    "    V13: float\n",
    "    V14: float\n",
    "    V15: float\n",
    "    V16: float\n",
    "    V17: float\n",
    "    V18: float\n",
    "    V19: float\n",
    "    V20: float\n",
    "    V21: float\n",
    "    V22: float\n",
    "    V23: float\n",
    "    V24: float\n",
    "    V25: float\n",
    "    V26: float\n",
    "    V27: float\n",
    "    V28: float\n",
    "    Amount: float\n",
    "    Hour: int\n",
    "\n",
    "@app.get(\"/\")\n",
    "def home():\n",
    "    return {\"message\": \"Credit Card Fraud Detection API is running!\"}\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "def predict(transaction: Transaction):\n",
    "    # Convert input data to DataFrame\n",
    "    input_data = pd.DataFrame([transaction.dict()])\n",
    "\n",
    "    # Apply preprocessing\n",
    "    input_scaled = preprocessor.transform(input_data)\n",
    "\n",
    "    # Make prediction\n",
    "    prediction = model.predict(input_scaled)\n",
    "    prediction_proba = model.predict_proba(input_scaled)[:, 1]\n",
    "\n",
    "    return {\n",
    "        \"fraud_prediction\": int(prediction[0]),\n",
    "        \"fraud_probability\": float(prediction_proba[0])\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/mahdi/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in /home/mahdi/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from lightgbm) (1.15.2)\n",
      "Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/mahdi/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/mahdi/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/mahdi/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/mahdi/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/mahdi/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
